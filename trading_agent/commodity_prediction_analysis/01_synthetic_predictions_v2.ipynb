{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%run \"./00_setup_and_config\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Generate Calibrated Synthetic Predictions - All Commodities\n",
        "\n",
        "**Improved accuracy definition:**\n",
        "- Point accuracy: Median prediction has target MAPE (e.g., 90% accurate = 10% MAPE)\n",
        "- Distribution calibration: Prediction intervals properly calibrated\n",
        "- Includes 100% accurate scenario (perfect foresight for testing)\n",
        "\n",
        "**Accuracy levels:**\n",
        "- 100% accurate: MAPE = 0% (all predictions exactly match actuals)\n",
        "- 90% accurate: MAPE = 10%\n",
        "- 80% accurate: MAPE = 20%\n",
        "- 70% accurate: MAPE = 30%\n",
        "- 60% accurate: MAPE = 40%"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "import gc\n",
        "import time\n",
        "from builtins import min as builtin_min, max as builtin_max"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Configuration\n",
        "SYNTHETIC_START_DATE = '2022-01-01'\n",
        "ACCURACY_LEVELS = [1.00, 0.90, 0.80, 0.70, 0.60]  # 100%, 90%, 80%, 70%, 60%\n",
        "\n",
        "print(f\"Synthetic prediction configuration:\")\n",
        "print(f\"  Synthetic start date: {SYNTHETIC_START_DATE}\")\n",
        "print(f\"  Accuracy levels: {[f'{a:.0%}' for a in ACCURACY_LEVELS]}\")\n",
        "print(f\"\\nAccuracy definition:\")\n",
        "print(f\"  - Point forecast: Median has target MAPE\")\n",
        "print(f\"  - Distribution: Calibrated prediction intervals\")\n",
        "print(f\"  - 100% accurate: Perfect foresight (MAPE = 0%)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Market Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "MARKET_TABLE = \"commodity.bronze.market\"\n",
        "print(f\"\\nLoading price data from {MARKET_TABLE}...\")\n",
        "\n",
        "market_df = spark.table(MARKET_TABLE).toPandas()\n",
        "market_df['date'] = pd.to_datetime(market_df['date'])\n",
        "\n",
        "print(f\"\u2713 Loaded market price data (FULL HISTORY)\")\n",
        "commodity_counts = market_df.groupby('commodity').size()\n",
        "print(f\"Available commodities:\")\n",
        "for commodity, count in commodity_counts.items():\n",
        "    print(f\"  - {commodity}: {count} rows\")\n",
        "print(f\"\\nDate range: {market_df['date'].min()} to {market_df['date'].max()}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Calibrated Prediction Generation\n",
        "\n",
        "Key improvements:\n",
        "1. **Target MAPE**: Median prediction has specified MAPE\n",
        "2. **Calibrated uncertainty**: Prediction spread reflects realistic uncertainty\n",
        "3. **100% accuracy**: Perfect scenario for algorithm testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_calibrated_predictions(prices_df, model_version, target_accuracy=0.90, \n",
        "                                    n_runs=2000, n_horizons=14, chunk_size=20):\n",
        "    \"\"\"\n",
        "    Generate calibrated synthetic predictions.\n",
        "    \n",
        "    Parameters:\n",
        "    - target_accuracy: 0.90 means median has 10% MAPE\n",
        "    - n_runs: Number of ensemble runs (2000)\n",
        "    - n_horizons: Forecast horizon (14 days)\n",
        "    \n",
        "    Returns:\n",
        "    - DataFrame with predictions having target MAPE and calibrated intervals\n",
        "    \"\"\"\n",
        "    n_dates = len(prices_df) - n_horizons\n",
        "    target_mape = 1.0 - target_accuracy  # 90% accurate = 10% MAPE\n",
        "    \n",
        "    print(f\"    Target MAPE: {target_mape:.1%}\")\n",
        "    print(f\"    Calibration: 80% interval should contain actual ~80% of time\")\n",
        "    \n",
        "    all_chunks = []\n",
        "    \n",
        "    for chunk_start in range(0, n_dates, chunk_size):\n",
        "        chunk_end = builtin_min(chunk_start + chunk_size, n_dates)\n",
        "        chunk_records = []\n",
        "        \n",
        "        for i in range(chunk_start, chunk_end):\n",
        "            current_date = prices_df.loc[i, 'date']\n",
        "            future_prices = prices_df.loc[i+1:i+n_horizons, 'price'].values\n",
        "            \n",
        "            if target_accuracy == 1.0:\n",
        "                # 100% accurate: All runs exactly match actual\n",
        "                predicted_prices_matrix = np.tile(future_prices, (n_runs, 1))\n",
        "            \n",
        "            else:\n",
        "                # Generate predictions with target MAPE\n",
        "                # Strategy: Add noise to actual such that median has target MAPE\n",
        "                \n",
        "                # 1. For each horizon day, generate median with target error\n",
        "                # Expected absolute error = target_mape * actual\n",
        "                # Use log-normal noise so median has target MAPE\n",
        "                # log(predicted/actual) ~ N(0, sigma\u00b2)\n",
        "                # We want E[|predicted - actual|/actual] = target_mape\n",
        "                # For log-normal: E[|exp(\u03b5)-1|] \u2248 sqrt(2/\u03c0) * sigma for small sigma\n",
        "                # So: sigma \u2248 target_mape * sqrt(\u03c0/2)\n",
        "                \n",
        "                sigma_lognormal = target_mape * np.sqrt(np.pi / 2)\n",
        "                \n",
        "                # Generate 2000 runs with calibrated uncertainty\n",
        "                # Use log-normal multiplicative errors\n",
        "                log_errors = np.random.normal(0, sigma_lognormal, (n_runs, n_horizons))\n",
        "                multiplicative_errors = np.exp(log_errors)\n",
        "                \n",
        "                # Apply to actual future prices\n",
        "                future_prices_matrix = np.tile(future_prices, (n_runs, 1))\n",
        "                predicted_prices_matrix = future_prices_matrix * multiplicative_errors\n",
        "                \n",
        "                # Add small run-specific bias for additional realism (\u00b12%)\n",
        "                run_biases = np.random.normal(1.0, 0.02, (n_runs, 1))\n",
        "                predicted_prices_matrix *= run_biases\n",
        "            \n",
        "            # Store predictions\n",
        "            for run_id in range(1, n_runs + 1):\n",
        "                for day_ahead in range(1, n_horizons + 1):\n",
        "                    chunk_records.append({\n",
        "                        'timestamp': current_date,\n",
        "                        'run_id': run_id,\n",
        "                        'day_ahead': day_ahead,\n",
        "                        'predicted_price': predicted_prices_matrix[run_id-1, day_ahead-1],\n",
        "                        'model_version': model_version\n",
        "                    })\n",
        "        \n",
        "        chunk_df = pd.DataFrame(chunk_records)\n",
        "        all_chunks.append(chunk_df)\n",
        "        \n",
        "        del chunk_records\n",
        "        gc.collect()\n",
        "        \n",
        "        if chunk_end % 100 == 0 or chunk_end == n_dates:\n",
        "            print(f\"    Progress: {chunk_end}/{n_dates} dates...\")\n",
        "    \n",
        "    final_df = pd.concat(all_chunks, ignore_index=True)\n",
        "    del all_chunks\n",
        "    gc.collect()\n",
        "    \n",
        "    return final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def validate_predictions(predictions_df, prices_df, target_accuracy, n_horizons=14):\n    \"\"\"\n    Validate that generated predictions have target accuracy.\n    Prints MAPE and calibration statistics.\n    \"\"\"\n    print(f\"\\n  Validating predictions...\")\n    \n    # Group by timestamp and day_ahead, compute median\n    medians = predictions_df.groupby(['timestamp', 'day_ahead'])['predicted_price'].median().reset_index()\n    medians.columns = ['timestamp', 'day_ahead', 'median_pred']\n    \n    # Get actual future prices\n    prices_df = prices_df.copy()\n    prices_df['date'] = pd.to_datetime(prices_df['date'])\n    \n    # Merge predictions with actuals\n    results = []\n    for _, row in medians.iterrows():\n        timestamp = row['timestamp']\n        day_ahead = int(row['day_ahead'])\n        median_pred = row['median_pred']\n        \n        # Find actual price day_ahead days after timestamp\n        future_date = timestamp + pd.Timedelta(days=day_ahead)\n        actual_row = prices_df[prices_df['date'] == future_date]\n        \n        if len(actual_row) > 0:\n            actual_price = actual_row['price'].values[0]\n            ape = abs(median_pred - actual_price) / actual_price\n            results.append({\n                'timestamp': timestamp,\n                'day_ahead': day_ahead,\n                'median_pred': median_pred,\n                'actual': actual_price,\n                'ape': ape\n            })\n    \n    if len(results) > 0:\n        results_df = pd.DataFrame(results)\n        overall_mape = results_df['ape'].mean()\n        target_mape = 1.0 - target_accuracy\n        \n        print(f\"    Overall MAPE: {overall_mape:.1%} (target: {target_mape:.1%})\")\n        print(f\"    Median APE: {results_df['ape'].median():.1%}\")\n        print(f\"    90th pct APE: {results_df['ape'].quantile(0.9):.1%}\")\n        \n        # Validate EACH horizon independently\n        print(f\"\\n    Per-Horizon MAPE (each should meet target {target_mape:.1%}):\")\n        per_horizon = results_df.groupby('day_ahead')['ape'].agg(['mean', 'median', 'count'])\n        for horizon in sorted(per_horizon.index):\n            horizon_mape = per_horizon.loc[horizon, 'mean']\n            horizon_count = int(per_horizon.loc[horizon, 'count'])\n            status = '\u2713' if horizon_mape <= target_mape * 1.15 else '\u26a0\ufe0f'  # Allow 15% tolerance\n            print(f\"      Day {horizon:2d}: {horizon_mape:5.1%} ({horizon_count:4d} samples) {status}\")\n        \n        # Check calibration (for non-100% accurate)\n        if target_accuracy < 1.0:\n            # Check if 80% interval contains actual ~80% of time\n            intervals = predictions_df.groupby(['timestamp', 'day_ahead'])['predicted_price'].agg(\n                p10=lambda x: x.quantile(0.1),\n                p90=lambda x: x.quantile(0.9)\n            ).reset_index()\n            \n            validation = results_df.merge(intervals, on=['timestamp', 'day_ahead'])\n            coverage_80 = ((validation['actual'] >= validation['p10']) & \n                          (validation['actual'] <= validation['p90'])).mean()\n            \n            print(f\"\\n    80% interval coverage: {coverage_80:.1%} (target: ~80%)\")\n    else:\n        print(f\"    \u26a0\ufe0f  Could not validate - no matching actuals found\")\n    \n    print(f\"  \u2713 Validation complete\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Process All Commodities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_single_commodity(commodity_name, prices_raw_pd, analysis_config, output_schema, \n",
        "                            accuracy_levels, synthetic_start_date):\n",
        "    \"\"\"\n",
        "    Process a single commodity with multiple calibrated accuracy levels.\n",
        "    \"\"\"\n",
        "    print(f\"\\n{'='*80}\")\n",
        "    print(f\"PROCESSING: {commodity_name.upper()}\")\n",
        "    print(f\"{'='*80}\")\n",
        "    \n",
        "    # Filter and prepare prices\n",
        "    print(f\"\\nPreparing price data...\")\n",
        "    prices_full = prices_raw_pd[prices_raw_pd['commodity'].str.lower() == commodity_name.lower()].copy()\n",
        "    prices_full['date'] = pd.to_datetime(prices_full['date'])\n",
        "    prices_full['price'] = prices_full['close']\n",
        "    prices_full = prices_full[['date', 'price']].sort_values('date').reset_index(drop=True)\n",
        "    \n",
        "    print(f\"\u2713 Full price history: {len(prices_full)} days\")\n",
        "    print(f\"  Date range: {prices_full['date'].min()} to {prices_full['date'].max()}\")\n",
        "    \n",
        "    # Filter to synthetic date range\n",
        "    print(f\"\\nFiltering to {synthetic_start_date}+ for synthetic predictions...\")\n",
        "    prices = prices_full[prices_full['date'] >= synthetic_start_date].copy().reset_index(drop=True)\n",
        "    print(f\"\u2713 Filtered to {len(prices)} days\")\n",
        "    \n",
        "    # Generate predictions for all accuracy levels\n",
        "    print(f\"\\nGenerating calibrated predictions for {len(accuracy_levels)} accuracy levels...\")\n",
        "    \n",
        "    all_predictions = []\n",
        "    \n",
        "    for accuracy in accuracy_levels:\n",
        "        model_version = f\"synthetic_acc{int(accuracy*100)}\"\n",
        "        \n",
        "        print(f\"\\n  {model_version}: {accuracy:.0%} accurate (MAPE = {(1-accuracy):.0%})\")\n",
        "        \n",
        "        start_time = time.time()\n",
        "        \n",
        "        predictions_df = generate_calibrated_predictions(\n",
        "            prices,\n",
        "            model_version=model_version,\n",
        "            target_accuracy=accuracy,\n",
        "            n_runs=analysis_config['prediction_runs'],\n",
        "            n_horizons=analysis_config['forecast_horizon'],\n",
        "            chunk_size=20\n",
        "        )\n",
        "        \n",
        "        elapsed = time.time() - start_time\n",
        "        print(f\"    \u2713 Generated {len(predictions_df):,} rows in {elapsed:.1f}s\")\n",
        "        \n",
        "        # Validate accuracy\n",
        "        validate_predictions(predictions_df, prices, accuracy, analysis_config['forecast_horizon'])\n",
        "        \n",
        "        all_predictions.append(predictions_df)\n",
        "        \n",
        "        del predictions_df\n",
        "        gc.collect()\n",
        "    \n",
        "    # Combine all accuracy levels\n",
        "    print(f\"\\nCombining all accuracy levels...\")\n",
        "    combined_predictions = pd.concat(all_predictions, ignore_index=True)\n",
        "    print(f\"\u2713 Combined: {len(combined_predictions):,} total rows\")\n",
        "    \n",
        "    del all_predictions\n",
        "    gc.collect()\n",
        "    \n",
        "    # Save to Delta table\n",
        "    predictions_table = f\"{output_schema}.predictions_{commodity_name.lower()}\"\n",
        "    \n",
        "    print(f\"\\nSaving to Delta table: {predictions_table}\")\n",
        "    predictions_spark = spark.createDataFrame(combined_predictions)\n",
        "    predictions_spark.write.mode(\"overwrite\").option(\"overwriteSchema\", \"true\").saveAsTable(predictions_table)\n",
        "    \n",
        "    saved_count = spark.table(predictions_table).count()\n",
        "    print(f\"\u2713 Saved and verified: {saved_count:,} rows\")\n",
        "    \n",
        "    del combined_predictions\n",
        "    gc.collect()\n",
        "    \n",
        "    print(f\"\\n\u2713 {commodity_name.upper()} COMPLETE\")\n",
        "    \n",
        "    return {\n",
        "        'commodity': commodity_name,\n",
        "        'n_dates': len(prices),\n",
        "        'n_accuracy_levels': len(accuracy_levels),\n",
        "        'table': predictions_table\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Process all commodities\n",
        "all_results = []\n",
        "\n",
        "for commodity_name in COMMODITY_CONFIGS.keys():\n",
        "    try:\n",
        "        result = process_single_commodity(\n",
        "            commodity_name,\n",
        "            market_df,\n",
        "            ANALYSIS_CONFIG,\n",
        "            OUTPUT_SCHEMA,\n",
        "            ACCURACY_LEVELS,\n",
        "            SYNTHETIC_START_DATE\n",
        "        )\n",
        "        all_results.append(result)\n",
        "    except Exception as e:\n",
        "        print(f\"\\n\u274c Error processing {commodity_name.upper()}: {e}\")\n",
        "        import traceback\n",
        "        traceback.print_exc()\n",
        "        print(f\"   Skipping...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print(\"\\n\" + \"=\"*80)\n",
        "print(\"CALIBRATED PREDICTION GENERATION COMPLETE\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "if len(all_results) > 0:\n",
        "    summary_df = pd.DataFrame(all_results)\n",
        "    print(f\"\\nSuccessfully processed {len(all_results)} commodities:\")\n",
        "    print(summary_df.to_string(index=False))\n",
        "    \n",
        "    print(f\"\\nPrediction tables created:\")\n",
        "    for table in sorted(summary_df['table'].unique()):\n",
        "        print(f\"  - {table}\")\n",
        "        model_versions = spark.table(table).select(\"model_version\").distinct().collect()\n",
        "        for mv in model_versions:\n",
        "            acc = int(mv.model_version.replace('synthetic_acc', ''))\n",
        "            mape = 100 - acc\n",
        "            print(f\"      \u2022 {mv.model_version}: {acc}% accurate (MAPE = {mape}%)\")\n",
        "    \n",
        "    print(f\"\\n\u2713 Key improvements over previous version:\")\n",
        "    print(f\"  1. Median predictions have target MAPE (e.g., 90% accurate = 10% MAPE)\")\n",
        "    print(f\"  2. Prediction intervals properly calibrated (80% interval \u2248 80% coverage)\")\n",
        "    print(f\"  3. Includes 100% accurate scenario for algorithm testing\")\n",
        "    print(f\"  4. Uses log-normal errors for realistic multiplicative noise\")\n",
        "else:\n",
        "    print(\"\\n\u26a0\ufe0f  No commodities were successfully processed\")\n",
        "\n",
        "print(\"\\n\u2713 Calibrated prediction generation complete\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}