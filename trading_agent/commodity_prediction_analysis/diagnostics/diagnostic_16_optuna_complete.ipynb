{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Diagnostic 16: Optuna Optimization - ALL 9 Strategies\n",
        "\n",
        "**Pure in-memory, no SQLite**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%run ../00_setup_and_config"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "%pip install optuna --quiet"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys, os, pandas as pd, numpy as np, pickle\n",
        "from datetime import datetime\n",
        "import optuna\n",
        "from optuna.samplers import TPESampler\n",
        "import importlib.util\n",
        "\n",
        "print('='*80)\n",
        "print('OPTUNA OPTIMIZATION - ALL 9 STRATEGIES')\n",
        "print('='*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "if 'all_strategies_pct' in sys.modules:\n",
        "    del sys.modules['all_strategies_pct']\n",
        "\n",
        "spec = importlib.util.spec_from_file_location('all_strategies_pct', 'all_strategies_pct.py')\n",
        "strat = importlib.util.module_from_spec(spec)\n",
        "spec.loader.exec_module(strat)\n",
        "\n",
        "ImmediateSaleStrategy = strat.ImmediateSaleStrategy\n",
        "EqualBatchStrategy = strat.EqualBatchStrategy\n",
        "PriceThresholdStrategy = strat.PriceThresholdStrategy\n",
        "MovingAverageStrategy = strat.MovingAverageStrategy\n",
        "PriceThresholdPredictive = strat.PriceThresholdPredictive\n",
        "MovingAveragePredictive = strat.MovingAveragePredictive\n",
        "ExpectedValueStrategy = strat.ExpectedValueStrategy\n",
        "ConsensusStrategy = strat.ConsensusStrategy\n",
        "RiskAdjustedStrategy = strat.RiskAdjustedStrategy\n",
        "\n",
        "print('✓ Loaded ALL 9 strategies')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "COMMODITY = 'coffee'\n",
        "MODEL_VERSION = 'synthetic_acc90'\n",
        "\n",
        "DATA_PATHS = get_data_paths(COMMODITY, MODEL_VERSION)\n",
        "COMMODITY_CONFIG = COMMODITY_CONFIGS[COMMODITY]\n",
        "\n",
        "COMMODITY_CONFIG['storage_cost_pct_per_day'] = 0.005\n",
        "COMMODITY_CONFIG['transaction_cost_pct'] = 0.01\n",
        "\n",
        "prices = spark.table(get_data_paths(COMMODITY)['prices_prepared']).toPandas()\n",
        "prices['date'] = pd.to_datetime(prices['date'])\n",
        "\n",
        "with open(DATA_PATHS['prediction_matrices'], 'rb') as f:\n",
        "    prediction_matrices = pickle.load(f)\n",
        "prediction_matrices = {pd.to_datetime(k): v for k, v in prediction_matrices.items()}\n",
        "\n",
        "print(f'✓ Loaded {len(prices)} prices, {len(prediction_matrices)} matrices')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Backtest Engine"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class Engine:\n",
        "    def __init__(self, prices_df, pred_matrices, config):\n",
        "        self.prices = prices_df\n",
        "        self.pred = pred_matrices\n",
        "        self.config = config\n",
        "    \n",
        "    def run_backtest(self, strategy, inv=50.0):\n",
        "        inventory, trades, rev, trans, stor = inv, [], 0, 0, 0\n",
        "        strategy.reset()\n",
        "        strategy.set_harvest_start(0)\n",
        "        \n",
        "        for day in range(len(self.prices)):\n",
        "            date = self.prices.iloc[day]['date']\n",
        "            price = self.prices.iloc[day]['price']\n",
        "            hist = self.prices.iloc[:day+1].copy()\n",
        "            pred = self.pred.get(date)\n",
        "            \n",
        "            dec = strategy.decide(day=day, inventory=inventory, current_price=price, price_history=hist, predictions=pred)\n",
        "            \n",
        "            if dec['action'] == 'SELL' and dec['amount'] > 0:\n",
        "                amt = min(dec['amount'], inventory)\n",
        "                r = amt * price * 20\n",
        "                t = r * self.config['transaction_cost_pct'] / 100\n",
        "                rev += r\n",
        "                trans += t\n",
        "                inventory -= amt\n",
        "            \n",
        "            if inventory > 0:\n",
        "                stor += inventory * self.prices.iloc[:day+1]['price'].mean() * 20 * self.config['storage_cost_pct_per_day'] / 100\n",
        "        \n",
        "        return {'net_earnings': rev - trans - stor, 'total_revenue': rev, 'num_trades': len(trades), 'storage_costs': stor, 'final_inventory': inventory}\n",
        "\n",
        "engine = Engine(prices, prediction_matrices, COMMODITY_CONFIG)\n",
        "print('✓ Engine ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Search Spaces - ALL 9 Strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_params(t, s):\n",
        "    if s == 'immediate_sale':\n",
        "        return {'min_batch_size': t.suggest_float('min_batch_size', 3.0, 10.0), 'sale_frequency_days': t.suggest_int('sale_frequency_days', 5, 14)}\n",
        "    \n",
        "    elif s == 'equal_batch':\n",
        "        return {'batch_size': t.suggest_float('batch_size', 0.15, 0.30), 'frequency_days': t.suggest_int('frequency_days', 20, 35)}\n",
        "    \n",
        "    elif s == 'price_threshold':\n",
        "        return {'threshold_pct': t.suggest_float('threshold_pct', 0.02, 0.07), 'batch_baseline': t.suggest_float('batch_baseline', 0.20, 0.35), 'batch_overbought_strong': t.suggest_float('batch_overbought_strong', 0.30, 0.40), 'batch_overbought': t.suggest_float('batch_overbought', 0.25, 0.35), 'batch_strong_trend': t.suggest_float('batch_strong_trend', 0.15, 0.25), 'rsi_overbought': t.suggest_int('rsi_overbought', 65, 75), 'rsi_moderate': t.suggest_int('rsi_moderate', 60, 70), 'adx_strong': t.suggest_int('adx_strong', 20, 30), 'cooldown_days': t.suggest_int('cooldown_days', 5, 10), 'max_days_without_sale': t.suggest_int('max_days_without_sale', 45, 75)}\n",
        "    \n",
        "    elif s == 'moving_average':\n",
        "        return {'ma_period': t.suggest_int('ma_period', 20, 35), 'batch_baseline': t.suggest_float('batch_baseline', 0.20, 0.30), 'batch_strong_momentum': t.suggest_float('batch_strong_momentum', 0.15, 0.25), 'batch_overbought': t.suggest_float('batch_overbought', 0.25, 0.35), 'batch_overbought_strong': t.suggest_float('batch_overbought_strong', 0.30, 0.40), 'rsi_overbought': t.suggest_int('rsi_overbought', 65, 75), 'rsi_min': t.suggest_int('rsi_min', 40, 50), 'adx_strong': t.suggest_int('adx_strong', 20, 30), 'adx_weak': t.suggest_int('adx_weak', 15, 25), 'cooldown_days': t.suggest_int('cooldown_days', 5, 10), 'max_days_without_sale': t.suggest_int('max_days_without_sale', 45, 75)}\n",
        "    \n",
        "    elif s == 'price_threshold_predictive':\n",
        "        return {'threshold_pct': t.suggest_float('threshold_pct', 0.02, 0.07), 'batch_baseline': t.suggest_float('batch_baseline', 0.20, 0.35), 'batch_overbought_strong': t.suggest_float('batch_overbought_strong', 0.30, 0.40), 'batch_overbought': t.suggest_float('batch_overbought', 0.25, 0.35), 'batch_strong_trend': t.suggest_float('batch_strong_trend', 0.15, 0.25), 'rsi_overbought': t.suggest_int('rsi_overbought', 65, 75), 'rsi_moderate': t.suggest_int('rsi_moderate', 60, 70), 'adx_strong': t.suggest_int('adx_strong', 20, 30), 'cooldown_days': t.suggest_int('cooldown_days', 5, 10), 'max_days_without_sale': t.suggest_int('max_days_without_sale', 45, 75), 'min_net_benefit_pct': t.suggest_float('min_net_benefit_pct', 0.3, 1.0), 'high_confidence_cv': t.suggest_float('high_confidence_cv', 0.03, 0.08), 'scenario_shift_aggressive': t.suggest_int('scenario_shift_aggressive', 1, 2), 'scenario_shift_conservative': t.suggest_int('scenario_shift_conservative', 1, 2)}\n",
        "    \n",
        "    elif s == 'moving_average_predictive':\n",
        "        return {'ma_period': t.suggest_int('ma_period', 20, 35), 'batch_baseline': t.suggest_float('batch_baseline', 0.20, 0.30), 'batch_strong_momentum': t.suggest_float('batch_strong_momentum', 0.15, 0.25), 'batch_overbought': t.suggest_float('batch_overbought', 0.25, 0.35), 'batch_overbought_strong': t.suggest_float('batch_overbought_strong', 0.30, 0.40), 'rsi_overbought': t.suggest_int('rsi_overbought', 65, 75), 'rsi_min': t.suggest_int('rsi_min', 40, 50), 'adx_strong': t.suggest_int('adx_strong', 20, 30), 'adx_weak': t.suggest_int('adx_weak', 15, 25), 'cooldown_days': t.suggest_int('cooldown_days', 5, 10), 'max_days_without_sale': t.suggest_int('max_days_without_sale', 45, 75), 'min_net_benefit_pct': t.suggest_float('min_net_benefit_pct', 0.3, 1.0), 'high_confidence_cv': t.suggest_float('high_confidence_cv', 0.03, 0.08), 'scenario_shift_aggressive': t.suggest_int('scenario_shift_aggressive', 1, 2), 'scenario_shift_conservative': t.suggest_int('scenario_shift_conservative', 1, 2)}\n",
        "    \n",
        "    elif s == 'expected_value':\n",
        "        return {'min_net_benefit_pct': t.suggest_float('min_net_benefit_pct', 0.3, 1.0), 'negative_threshold_pct': t.suggest_float('negative_threshold_pct', -0.5, -0.1), 'high_confidence_cv': t.suggest_float('high_confidence_cv', 0.03, 0.08), 'medium_confidence_cv': t.suggest_float('medium_confidence_cv', 0.10, 0.15), 'strong_trend_adx': t.suggest_int('strong_trend_adx', 20, 25), 'batch_positive_confident': t.suggest_float('batch_positive_confident', 0.0, 0.05), 'batch_positive_uncertain': t.suggest_float('batch_positive_uncertain', 0.10, 0.20), 'batch_marginal': t.suggest_float('batch_marginal', 0.15, 0.20), 'batch_negative_mild': t.suggest_float('batch_negative_mild', 0.25, 0.30), 'batch_negative_strong': t.suggest_float('batch_negative_strong', 0.35, 0.40), 'cooldown_days': t.suggest_int('cooldown_days', 5, 7), 'baseline_batch': t.suggest_float('baseline_batch', 0.15, 0.20), 'baseline_frequency': t.suggest_int('baseline_frequency', 25, 30)}\n",
        "    \n",
        "    elif s == 'consensus':\n",
        "        return {'consensus_threshold': t.suggest_float('consensus_threshold', 0.60, 0.75), 'very_strong_consensus': t.suggest_float('very_strong_consensus', 0.80, 0.85), 'moderate_consensus': t.suggest_float('moderate_consensus', 0.55, 0.60), 'min_return': t.suggest_float('min_return', 0.02, 0.05), 'min_net_benefit_pct': t.suggest_float('min_net_benefit_pct', 0.3, 0.7), 'high_confidence_cv': t.suggest_float('high_confidence_cv', 0.03, 0.08), 'batch_strong_consensus': t.suggest_float('batch_strong_consensus', 0.0, 0.05), 'batch_moderate': t.suggest_float('batch_moderate', 0.10, 0.20), 'batch_weak': t.suggest_float('batch_weak', 0.25, 0.30), 'batch_bearish': t.suggest_float('batch_bearish', 0.35, 0.40), 'evaluation_day': t.suggest_int('evaluation_day', 10, 14), 'cooldown_days': t.suggest_int('cooldown_days', 5, 7)}\n",
        "    \n",
        "    elif s == 'risk_adjusted':\n",
        "        return {'min_return': t.suggest_float('min_return', 0.02, 0.05), 'min_net_benefit_pct': t.suggest_float('min_net_benefit_pct', 0.3, 0.7), 'max_uncertainty_low': t.suggest_float('max_uncertainty_low', 0.03, 0.08), 'max_uncertainty_medium': t.suggest_float('max_uncertainty_medium', 0.10, 0.20), 'max_uncertainty_high': t.suggest_float('max_uncertainty_high', 0.25, 0.35), 'strong_trend_adx': t.suggest_int('strong_trend_adx', 20, 25), 'batch_low_risk': t.suggest_float('batch_low_risk', 0.0, 0.05), 'batch_medium_risk': t.suggest_float('batch_medium_risk', 0.10, 0.15), 'batch_high_risk': t.suggest_float('batch_high_risk', 0.25, 0.30), 'batch_very_high_risk': t.suggest_float('batch_very_high_risk', 0.35, 0.40), 'evaluation_day': t.suggest_int('evaluation_day', 10, 14), 'cooldown_days': t.suggest_int('cooldown_days', 5, 7)}\n",
        "    \n",
        "    raise ValueError(f'Unknown strategy: {s}')\n",
        "\n",
        "print('✓ ALL search spaces defined')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Optimize Function - Pure In-Memory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def opt(cls, name, n=200):\n",
        "    print(f\"\\n{'='*80}\\n{name}: {n} trials\\n{'='*80}\")\n",
        "    \n",
        "    # Pure in-memory study - NO SQLite\n",
        "    study = optuna.create_study(direction='maximize', sampler=TPESampler(seed=42))\n",
        "    \n",
        "    def obj(trial):\n",
        "        p = get_params(trial, name)\n",
        "        \n",
        "        # Add costs for prediction strategies\n",
        "        if name not in ['immediate_sale', 'equal_batch', 'price_threshold', 'moving_average']:\n",
        "            p['storage_cost_pct_per_day'] = COMMODITY_CONFIG['storage_cost_pct_per_day']\n",
        "            p['transaction_cost_pct'] = COMMODITY_CONFIG['transaction_cost_pct']\n",
        "        \n",
        "        try:\n",
        "            s = cls(**p)\n",
        "            return engine.run_backtest(s)['net_earnings']\n",
        "        except Exception as e:\n",
        "            return -1e9\n",
        "    \n",
        "    study.optimize(obj, n_trials=n, show_progress_bar=True)\n",
        "    print(f'✓ Best: ${study.best_value:,.2f}')\n",
        "    return study.best_params, study\n",
        "\n",
        "print('✓ Optimize function ready')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Run ALL 9 Strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "results = {}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 1. Immediate Sale"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p, s = opt(ImmediateSaleStrategy, 'immediate_sale', 200)\n",
        "results['immediate_sale'] = (p, s.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 2. Equal Batch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p, s = opt(EqualBatchStrategy, 'equal_batch', 200)\n",
        "results['equal_batch'] = (p, s.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 3. Price Threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p, s = opt(PriceThresholdStrategy, 'price_threshold', 200)\n",
        "results['price_threshold'] = (p, s.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 4. Moving Average"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p, s = opt(MovingAverageStrategy, 'moving_average', 200)\n",
        "results['moving_average'] = (p, s.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 5. PT Predictive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p, s = opt(PriceThresholdPredictive, 'price_threshold_predictive', 200)\n",
        "results['price_threshold_predictive'] = (p, s.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 6. MA Predictive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p, s = opt(MovingAveragePredictive, 'moving_average_predictive', 200)\n",
        "results['moving_average_predictive'] = (p, s.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 7. Expected Value"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p, s = opt(ExpectedValueStrategy, 'expected_value', 200)\n",
        "results['expected_value'] = (p, s.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 8. Consensus"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p, s = opt(ConsensusStrategy, 'consensus', 200)\n",
        "results['consensus'] = (p, s.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### 9. Risk-Adjusted"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "p, s = opt(RiskAdjustedStrategy, 'risk_adjusted', 200)\n",
        "results['risk_adjusted'] = (p, s.best_value)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\n' + '='*80)\n",
        "print('ALL 9 STRATEGIES COMPLETE')\n",
        "print('='*80)\n",
        "for n, (p, v) in sorted(results.items(), key=lambda x: x[1][1], reverse=True):\n",
        "    print(f'{n:35s}: ${v:,.2f}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Display Best Parameters"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "print('\\n' + '='*80)\n",
        "print('BEST PARAMETERS FOR EACH STRATEGY')\n",
        "print('='*80)\n",
        "\n",
        "for strategy_name, (params, value) in results.items():\n",
        "    print(f'\\n{strategy_name}: ${value:,.2f}')\n",
        "    print('-' * 40)\n",
        "    for param, val in sorted(params.items()):\n",
        "        print(f'  {param:30s}: {val}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Save Best Parameters for Diagnostic 17"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract just the parameters (not the values) for diagnostic 17\n",
        "best_params = {name: params for name, (params, value) in results.items()}\n",
        "\n",
        "# Add cost parameters to predictive strategies\n",
        "for strategy in ['price_threshold_predictive', 'moving_average_predictive', 'expected_value', 'consensus', 'risk_adjusted']:\n",
        "    if strategy in best_params:\n",
        "        best_params[strategy]['storage_cost_pct_per_day'] = COMMODITY_CONFIG['storage_cost_pct_per_day']\n",
        "        best_params[strategy]['transaction_cost_pct'] = COMMODITY_CONFIG['transaction_cost_pct']\n",
        "\n",
        "# Save to pickle file\n",
        "output_path = 'diagnostic_16_best_params.pkl'\n",
        "with open(output_path, 'wb') as f:\n",
        "    pickle.dump(best_params, f)\n",
        "\n",
        "print(f'\\n✓ Saved best parameters to {output_path}')\n",
        "print(f'  Diagnostic 17 will automatically load these parameters')"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
