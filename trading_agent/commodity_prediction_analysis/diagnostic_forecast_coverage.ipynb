{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DIAGNOSTIC: FORECAST COVERAGE IN DISTRIBUTIONS TABLE\n",
    "# ============================================================================\n",
    "# Purpose: Comprehensive check of what forecasts are available per model\n",
    "# \n",
    "# This diagnostic answers:\n",
    "# 1. How many unique forecast dates exist per model?\n",
    "# 2. What is the date range coverage?\n",
    "# 3. Are there gaps in the forecast dates?\n",
    "# 4. How many paths per forecast date?\n",
    "# 5. What is the actual vs expected forecast density?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime, timedelta\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "FORECAST_TABLE = 'commodity.forecast.distributions'\n",
    "COMMODITIES = ['coffee', 'sugar']\n",
    "\n",
    "print(f\"Querying: {FORECAST_TABLE}\")\n",
    "print(f\"Commodities: {COMMODITIES}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-3",
   "metadata": {},
   "source": [
    "## Step 1: Get All Models and Date Ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query all forecasts (not actuals) to see what's available\n",
    "query = f\"\"\"\n",
    "SELECT \n",
    "    commodity,\n",
    "    model_version,\n",
    "    COUNT(DISTINCT forecast_start_date) as n_forecast_dates,\n",
    "    MIN(forecast_start_date) as first_forecast,\n",
    "    MAX(forecast_start_date) as last_forecast,\n",
    "    COUNT(DISTINCT path_id) as n_paths_per_date,\n",
    "    COUNT(*) as total_rows\n",
    "FROM {FORECAST_TABLE}\n",
    "WHERE is_actuals = FALSE\n",
    "GROUP BY commodity, model_version\n",
    "ORDER BY commodity, model_version\n",
    "\"\"\"\n",
    "\n",
    "summary_df = spark.sql(query).toPandas()\n",
    "\n",
    "print(\"=\" * 100)\n",
    "print(\"FORECAST AVAILABILITY SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "print(summary_df.to_string(index=False))\n",
    "print(f\"\\nTotal models found: {len(summary_df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-5",
   "metadata": {},
   "source": [
    "## Step 2: Detailed Analysis Per Commodity and Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_forecast_coverage(commodity, model_version):\n",
    "    \"\"\"\n",
    "    Detailed analysis of forecast coverage for a specific commodity-model pair.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get all forecast dates for this model\n",
    "    query = f\"\"\"\n",
    "    SELECT DISTINCT \n",
    "        forecast_start_date,\n",
    "        COUNT(DISTINCT path_id) as n_paths\n",
    "    FROM {FORECAST_TABLE}\n",
    "    WHERE commodity = '{commodity.capitalize()}'\n",
    "      AND model_version = '{model_version}'\n",
    "      AND is_actuals = FALSE\n",
    "    GROUP BY forecast_start_date\n",
    "    ORDER BY forecast_start_date\n",
    "    \"\"\"\n",
    "    \n",
    "    dates_df = spark.sql(query).toPandas()\n",
    "    dates_df['forecast_start_date'] = pd.to_datetime(dates_df['forecast_start_date'])\n",
    "    \n",
    "    if len(dates_df) == 0:\n",
    "        print(f\"\\nâš ï¸  No forecasts found for {commodity} - {model_version}\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate gaps\n",
    "    dates_df = dates_df.sort_values('forecast_start_date').reset_index(drop=True)\n",
    "    dates_df['days_since_prev'] = dates_df['forecast_start_date'].diff().dt.days\n",
    "    \n",
    "    # Analysis\n",
    "    first_date = dates_df['forecast_start_date'].min()\n",
    "    last_date = dates_df['forecast_start_date'].max()\n",
    "    total_days = (last_date - first_date).days\n",
    "    n_forecasts = len(dates_df)\n",
    "    \n",
    "    # Expected forecasts if 14-day cadence\n",
    "    expected_forecasts_14d = total_days // 14 + 1\n",
    "    coverage_pct = (n_forecasts / expected_forecasts_14d * 100) if expected_forecasts_14d > 0 else 0\n",
    "    \n",
    "    # Gap analysis\n",
    "    gaps = dates_df['days_since_prev'].dropna()\n",
    "    avg_gap = gaps.mean() if len(gaps) > 0 else 0\n",
    "    max_gap = gaps.max() if len(gaps) > 0 else 0\n",
    "    \n",
    "    # Paths per date\n",
    "    avg_paths = dates_df['n_paths'].mean()\n",
    "    min_paths = dates_df['n_paths'].min()\n",
    "    max_paths = dates_df['n_paths'].max()\n",
    "    \n",
    "    print(f\"\\n{'='*100}\")\n",
    "    print(f\"{commodity.upper()} - {model_version}\")\n",
    "    print(f\"{'='*100}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“… DATE COVERAGE:\")\n",
    "    print(f\"  First forecast: {first_date.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Last forecast:  {last_date.strftime('%Y-%m-%d')}\")\n",
    "    print(f\"  Total span:     {total_days} days ({total_days/365:.1f} years)\")\n",
    "    print(f\"  Forecast dates: {n_forecasts}\")\n",
    "    \n",
    "    print(f\"\\nðŸ“Š DENSITY:\")\n",
    "    print(f\"  Expected (14-day cadence): {expected_forecasts_14d} forecasts\")\n",
    "    print(f\"  Actual coverage:           {coverage_pct:.1f}%\")\n",
    "    print(f\"  Average gap:               {avg_gap:.1f} days\")\n",
    "    print(f\"  Maximum gap:               {max_gap:.0f} days\")\n",
    "    \n",
    "    print(f\"\\nðŸ”¢ PATHS PER FORECAST:\")\n",
    "    print(f\"  Average: {avg_paths:.0f}\")\n",
    "    print(f\"  Min:     {min_paths}\")\n",
    "    print(f\"  Max:     {max_paths}\")\n",
    "    \n",
    "    # Show gap distribution\n",
    "    if len(gaps) > 0:\n",
    "        print(f\"\\nðŸ“ˆ GAP DISTRIBUTION:\")\n",
    "        gap_counts = gaps.value_counts().sort_index()\n",
    "        for gap_days, count in gap_counts.head(10).items():\n",
    "            print(f\"  {gap_days:3.0f} days: {count:3d} occurrences\")\n",
    "        \n",
    "        if len(gap_counts) > 10:\n",
    "            print(f\"  ... ({len(gap_counts) - 10} more gap sizes)\")\n",
    "    \n",
    "    # Large gaps (>30 days)\n",
    "    large_gaps = dates_df[dates_df['days_since_prev'] > 30]\n",
    "    if len(large_gaps) > 0:\n",
    "        print(f\"\\nâš ï¸  LARGE GAPS (>30 days):\")\n",
    "        for idx, row in large_gaps.iterrows():\n",
    "            prev_date = dates_df.loc[idx-1, 'forecast_start_date'] if idx > 0 else None\n",
    "            if prev_date:\n",
    "                print(f\"  {prev_date.strftime('%Y-%m-%d')} â†’ {row['forecast_start_date'].strftime('%Y-%m-%d')}: {row['days_since_prev']:.0f} days\")\n",
    "    \n",
    "    # Show first and last 10 dates\n",
    "    print(f\"\\nðŸ“‹ FIRST 10 FORECAST DATES:\")\n",
    "    for idx, row in dates_df.head(10).iterrows():\n",
    "        print(f\"  {row['forecast_start_date'].strftime('%Y-%m-%d')}: {row['n_paths']} paths\")\n",
    "    \n",
    "    if len(dates_df) > 10:\n",
    "        print(f\"\\nðŸ“‹ LAST 10 FORECAST DATES:\")\n",
    "        for idx, row in dates_df.tail(10).iterrows():\n",
    "            print(f\"  {row['forecast_start_date'].strftime('%Y-%m-%d')}: {row['n_paths']} paths\")\n",
    "    \n",
    "    return dates_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run detailed analysis for each commodity-model pair\n",
    "all_coverage_data = {}\n",
    "\n",
    "for _, row in summary_df.iterrows():\n",
    "    commodity = row['commodity'].lower()\n",
    "    model_version = row['model_version']\n",
    "    \n",
    "    coverage_df = analyze_forecast_coverage(commodity, model_version)\n",
    "    \n",
    "    if coverage_df is not None:\n",
    "        all_coverage_data[f\"{commodity}_{model_version}\"] = coverage_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-8",
   "metadata": {},
   "source": [
    "## Step 3: Visual Timeline of Forecast Coverage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create visualization of forecast coverage for each model\n",
    "fig, axes = plt.subplots(len(summary_df), 1, figsize=(16, 3 * len(summary_df)))\n",
    "\n",
    "if len(summary_df) == 1:\n",
    "    axes = [axes]\n",
    "\n",
    "for idx, (key, coverage_df) in enumerate(all_coverage_data.items()):\n",
    "    ax = axes[idx]\n",
    "    \n",
    "    # Plot forecast dates as vertical lines\n",
    "    dates = coverage_df['forecast_start_date']\n",
    "    y_vals = np.ones(len(dates))\n",
    "    \n",
    "    ax.scatter(dates, y_vals, marker='|', s=100, c='blue', alpha=0.6)\n",
    "    \n",
    "    # Highlight large gaps\n",
    "    large_gaps = coverage_df[coverage_df['days_since_prev'] > 30]\n",
    "    if len(large_gaps) > 0:\n",
    "        for idx_gap, row in large_gaps.iterrows():\n",
    "            if idx_gap > 0:\n",
    "                prev_date = coverage_df.loc[idx_gap-1, 'forecast_start_date']\n",
    "                curr_date = row['forecast_start_date']\n",
    "                ax.axvspan(prev_date, curr_date, alpha=0.2, color='red')\n",
    "    \n",
    "    ax.set_ylim([0.5, 1.5])\n",
    "    ax.set_yticks([])\n",
    "    ax.set_xlabel('Date')\n",
    "    ax.set_title(f\"{key.upper()} - Forecast Coverage Timeline (red = gaps >30 days)\")\n",
    "    ax.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('/tmp/forecast_coverage_timeline.png', dpi=150, bbox_inches='tight')\n",
    "print(\"\\nâœ“ Saved timeline visualization: /tmp/forecast_coverage_timeline.png\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-10",
   "metadata": {},
   "source": [
    "## Step 4: Check for Continuous Coverage Potential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if there are any models with near-continuous coverage\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"CONTINUOUS COVERAGE ASSESSMENT\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "for key, coverage_df in all_coverage_data.items():\n",
    "    gaps = coverage_df['days_since_prev'].dropna()\n",
    "    \n",
    "    # Count forecasts within different gap tolerances\n",
    "    n_total = len(coverage_df)\n",
    "    n_within_14d = sum(gaps <= 14) if len(gaps) > 0 else 0\n",
    "    n_within_21d = sum(gaps <= 21) if len(gaps) > 0 else 0\n",
    "    n_within_30d = sum(gaps <= 30) if len(gaps) > 0 else 0\n",
    "    \n",
    "    pct_14d = (n_within_14d / len(gaps) * 100) if len(gaps) > 0 else 0\n",
    "    pct_21d = (n_within_21d / len(gaps) * 100) if len(gaps) > 0 else 0\n",
    "    pct_30d = (n_within_30d / len(gaps) * 100) if len(gaps) > 0 else 0\n",
    "    \n",
    "    print(f\"\\n{key.upper()}:\")\n",
    "    print(f\"  Total forecasts: {n_total}\")\n",
    "    print(f\"  Gaps â‰¤14 days: {n_within_14d}/{len(gaps)} ({pct_14d:.1f}%)\")\n",
    "    print(f\"  Gaps â‰¤21 days: {n_within_21d}/{len(gaps)} ({pct_21d:.1f}%)\")\n",
    "    print(f\"  Gaps â‰¤30 days: {n_within_30d}/{len(gaps)} ({pct_30d:.1f}%)\")\n",
    "    \n",
    "    if pct_14d >= 80:\n",
    "        print(f\"  âœ“ GOOD: {pct_14d:.1f}% of gaps are â‰¤14 days (near-continuous)\")\n",
    "    elif pct_21d >= 80:\n",
    "        print(f\"  âš ï¸  MODERATE: {pct_21d:.1f}% of gaps are â‰¤21 days (somewhat sparse)\")\n",
    "    else:\n",
    "        print(f\"  âŒ SPARSE: Only {pct_30d:.1f}% of gaps are â‰¤30 days (very sparse)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cell-12",
   "metadata": {},
   "source": [
    "## Step 5: Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cell-13",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"FINAL SUMMARY\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(f\"\\nTotal models analyzed: {len(all_coverage_data)}\")\n",
    "\n",
    "# Group by commodity\n",
    "for commodity in COMMODITIES:\n",
    "    commodity_models = [k for k in all_coverage_data.keys() if k.startswith(commodity)]\n",
    "    \n",
    "    if commodity_models:\n",
    "        print(f\"\\n{commodity.upper()}:\")\n",
    "        print(f\"  Models: {len(commodity_models)}\")\n",
    "        \n",
    "        total_forecasts = sum([len(all_coverage_data[k]) for k in commodity_models])\n",
    "        avg_forecasts = total_forecasts / len(commodity_models)\n",
    "        \n",
    "        print(f\"  Total forecast dates across all models: {total_forecasts}\")\n",
    "        print(f\"  Average per model: {avg_forecasts:.1f}\")\n",
    "        \n",
    "        # Find model with most coverage\n",
    "        best_model = max(commodity_models, key=lambda k: len(all_coverage_data[k]))\n",
    "        best_count = len(all_coverage_data[best_model])\n",
    "        print(f\"  Best coverage: {best_model.split('_', 1)[1]} ({best_count} forecasts)\")\n",
    "\n",
    "print(\"\\n\" + \"=\" * 100)\n",
    "print(\"âœ“ DIAGNOSTIC COMPLETE\")\n",
    "print(\"=\" * 100)\n",
    "\n",
    "print(\"\\nNEXT STEPS:\")\n",
    "print(\"1. Review the gap distributions above\")\n",
    "print(\"2. Check if large gaps (>30 days) are expected or data issues\")\n",
    "print(\"3. Verify with forecast team if sparse coverage is intentional\")\n",
    "print(\"4. If continuous forecasts exist, they may be in a different table/filter\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
