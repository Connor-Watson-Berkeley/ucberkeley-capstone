{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run ./00_setup_and_config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Synthetic Accuracy Comparison\n",
    "\n",
    "**Purpose:** Compare trading strategy performance across synthetic prediction accuracy levels (60%, 70%, 80%, 90%)\n",
    "\n",
    "**Critical Validation:**\n",
    "- If 90% accuracy doesn't show advantage ‚Üí Trading logic has bugs\n",
    "- Performance should improve monotonically with accuracy\n",
    "- Identify accuracy threshold where predictions become valuable\n",
    "\n",
    "**Strategies Tested:** All 9 strategies (4 baselines, 5 prediction-based)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import pickle\n",
    "\n",
    "# Set visualization style\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"SYNTHETIC ACCURACY COMPARISON ANALYSIS\")\n",
    "print(\"=\" * 80)\n",
    "print(\"\\nThis notebook validates trading logic by comparing performance\")\n",
    "print(\"across controlled accuracy levels: 60%, 70%, 80%, 90%\")\n",
    "print(\"\\n‚ö†Ô∏è  CRITICAL: If 90% accuracy doesn't beat baselines, logic is broken!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": "# Synthetic model versions (generated by notebook 01)\nSYNTHETIC_ACCURACIES = [100, 90, 80, 70, 60]  # Added 100% - CRITICAL TEST\nSYNTHETIC_MODELS = [f'synthetic_acc{acc}' for acc in SYNTHETIC_ACCURACIES]\n\n# Strategy groups\nBASELINE_STRATEGIES = ['Immediate Sale', 'Equal Batches', 'Price Threshold', 'Moving Average']\nPREDICTION_STRATEGIES = ['Consensus', 'Expected Value', 'Risk-Adjusted', \n                        'Price Threshold Predictive', 'Moving Average Predictive']\n\n# Color scheme\nACCURACY_COLORS = {\n    100: '#27ae60',  # Dark Green - PERFECT\n    90: '#2ecc71',   # Green\n    80: '#f1c40f',   # Yellow\n    70: '#f39c12',   # Orange\n    60: '#e74c3c'    # Red\n}\n\nprint(f\"\\n‚ö†Ô∏è  CRITICAL: 100% accuracy = PERFECT FORESIGHT\")\nprint(f\"   If strategies can't beat baselines with 100% accuracy, algo is BROKEN!\")\nprint(f\"\\nAccuracy levels to compare: {SYNTHETIC_ACCURACIES}\")\nprint(f\"Commodities: {list(COMMODITY_CONFIGS.keys())}\")\nprint(f\"Baseline strategies: {len(BASELINE_STRATEGIES)}\")\nprint(f\"Prediction strategies: {len(PREDICTION_STRATEGIES)}\")"
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Results for All Accuracy Levels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store all results\n",
    "all_results = {}\n",
    "\n",
    "for COMMODITY in COMMODITY_CONFIGS.keys():\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"LOADING RESULTS: {COMMODITY.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    all_results[COMMODITY] = {}\n",
    "    \n",
    "    for model_version in SYNTHETIC_MODELS:\n",
    "        accuracy = int(model_version.split('acc')[1])\n",
    "        \n",
    "        print(f\"\\n  Loading {accuracy}% accuracy results...\")\n",
    "        \n",
    "        try:\n",
    "            # Get data paths for this model version\n",
    "            paths = get_data_paths(COMMODITY, model_version)\n",
    "            \n",
    "            # Load results from Delta table\n",
    "            results_df = spark.table(paths['results']).toPandas()\n",
    "            \n",
    "            # Load detailed results (for trade-level analysis)\n",
    "            with open(paths['results_detailed'], 'rb') as f:\n",
    "                results_detailed = pickle.load(f)\n",
    "            \n",
    "            all_results[COMMODITY][accuracy] = {\n",
    "                'summary': results_df,\n",
    "                'detailed': results_detailed\n",
    "            }\n",
    "            \n",
    "            print(f\"    ‚úì Loaded {len(results_df)} strategy results\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"    ‚ö†Ô∏è  Could not load {accuracy}% results: {e}\")\n",
    "            print(f\"    Note: You may need to run notebook 05 first to generate results\")\n",
    "\n",
    "print(f\"\\n{'='*80}\")\n",
    "print(\"LOADING COMPLETE\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Check what was loaded\n",
    "for commodity, accuracy_results in all_results.items():\n",
    "    print(f\"\\n{commodity.upper()}: Loaded {len(accuracy_results)} accuracy levels\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 1: Performance vs Accuracy Curves"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for COMMODITY in COMMODITY_CONFIGS.keys():\n",
    "    if COMMODITY not in all_results or len(all_results[COMMODITY]) == 0:\n",
    "        print(f\"\\n‚ö†Ô∏è  No results for {COMMODITY.upper()} - skipping\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"PERFORMANCE VS ACCURACY ANALYSIS: {COMMODITY.upper()}\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    commodity_results = all_results[COMMODITY]\n",
    "    \n",
    "    # Collect data for visualization\n",
    "    accuracy_data = []\n",
    "    \n",
    "    for accuracy in sorted(commodity_results.keys()):\n",
    "        summary_df = commodity_results[accuracy]['summary']\n",
    "        \n",
    "        for _, row in summary_df.iterrows():\n",
    "            accuracy_data.append({\n",
    "                'accuracy': accuracy,\n",
    "                'strategy': row['strategy'],\n",
    "                'type': row['type'],\n",
    "                'net_earnings': row['net_earnings'],\n",
    "                'total_revenue': row['total_revenue'],\n",
    "                'avg_sale_price': row['avg_sale_price'],\n",
    "                'n_trades': row['n_trades'],\n",
    "                'total_costs': row['total_costs']\n",
    "            })\n",
    "    \n",
    "    accuracy_df = pd.DataFrame(accuracy_data)\n",
    "    \n",
    "    # Create comprehensive comparison figure\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(20, 12))\n",
    "    fig.suptitle(f'{COMMODITY.title()} - Performance vs Prediction Accuracy', \n",
    "                 fontsize=18, fontweight='bold', y=0.995)\n",
    "    \n",
    "    # Plot 1: Net Earnings vs Accuracy (All Strategies)\n",
    "    ax1 = axes[0, 0]\n",
    "    for strategy in accuracy_df['strategy'].unique():\n",
    "        strat_data = accuracy_df[accuracy_df['strategy'] == strategy]\n",
    "        is_prediction = strategy in PREDICTION_STRATEGIES\n",
    "        \n",
    "        ax1.plot(strat_data['accuracy'], strat_data['net_earnings'],\n",
    "                marker='o', linewidth=2 if is_prediction else 1,\n",
    "                linestyle='-' if is_prediction else '--',\n",
    "                alpha=0.9 if is_prediction else 0.6,\n",
    "                label=strategy)\n",
    "    \n",
    "    ax1.set_xlabel('Prediction Accuracy (%)', fontweight='bold')\n",
    "    ax1.set_ylabel('Net Earnings ($)', fontweight='bold')\n",
    "    ax1.set_title('Net Earnings vs Accuracy', fontweight='bold')\n",
    "    ax1.legend(bbox_to_anchor=(1.05, 1), loc='upper left', fontsize=8)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xticks(SYNTHETIC_ACCURACIES)\n",
    "    \n",
    "    # Plot 2: Prediction Strategies Only (Cleaner View)\n",
    "    ax2 = axes[0, 1]\n",
    "    pred_data = accuracy_df[accuracy_df['strategy'].isin(PREDICTION_STRATEGIES)]\n",
    "    \n",
    "    for strategy in PREDICTION_STRATEGIES:\n",
    "        strat_data = pred_data[pred_data['strategy'] == strategy]\n",
    "        ax2.plot(strat_data['accuracy'], strat_data['net_earnings'],\n",
    "                marker='o', linewidth=2.5, label=strategy)\n",
    "    \n",
    "    ax2.set_xlabel('Prediction Accuracy (%)', fontweight='bold')\n",
    "    ax2.set_ylabel('Net Earnings ($)', fontweight='bold')\n",
    "    ax2.set_title('Prediction Strategies Only', fontweight='bold')\n",
    "    ax2.legend(fontsize=9)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xticks(SYNTHETIC_ACCURACIES)\n",
    "    \n",
    "    # Plot 3: Best Prediction vs Best Baseline\n",
    "    ax3 = axes[0, 2]\n",
    "    \n",
    "    best_by_accuracy = []\n",
    "    for accuracy in SYNTHETIC_ACCURACIES:\n",
    "        acc_data = accuracy_df[accuracy_df['accuracy'] == accuracy]\n",
    "        \n",
    "        baseline_data = acc_data[acc_data['strategy'].isin(BASELINE_STRATEGIES)]\n",
    "        pred_data_local = acc_data[acc_data['strategy'].isin(PREDICTION_STRATEGIES)]\n",
    "        \n",
    "        best_baseline = baseline_data['net_earnings'].max() if len(baseline_data) > 0 else 0\n",
    "        best_prediction = pred_data_local['net_earnings'].max() if len(pred_data_local) > 0 else 0\n",
    "        \n",
    "        best_by_accuracy.append({\n",
    "            'accuracy': accuracy,\n",
    "            'best_baseline': best_baseline,\n",
    "            'best_prediction': best_prediction,\n",
    "            'advantage': best_prediction - best_baseline\n",
    "        })\n",
    "    \n",
    "    best_df = pd.DataFrame(best_by_accuracy)\n",
    "    \n",
    "    ax3.plot(best_df['accuracy'], best_df['best_baseline'],\n",
    "            marker='s', linewidth=2.5, label='Best Baseline', color='steelblue')\n",
    "    ax3.plot(best_df['accuracy'], best_df['best_prediction'],\n",
    "            marker='o', linewidth=2.5, label='Best Prediction', color='orangered')\n",
    "    \n",
    "    ax3.set_xlabel('Prediction Accuracy (%)', fontweight='bold')\n",
    "    ax3.set_ylabel('Net Earnings ($)', fontweight='bold')\n",
    "    ax3.set_title('Best Strategy per Category', fontweight='bold')\n",
    "    ax3.legend(fontsize=10)\n",
    "    ax3.grid(True, alpha=0.3)\n",
    "    ax3.set_xticks(SYNTHETIC_ACCURACIES)\n",
    "    \n",
    "    # Plot 4: Prediction Advantage ($)\n",
    "    ax4 = axes[1, 0]\n",
    "    \n",
    "    colors = [ACCURACY_COLORS[acc] for acc in best_df['accuracy']]\n",
    "    bars = ax4.bar(best_df['accuracy'], best_df['advantage'], \n",
    "                   color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, best_df['advantage']):\n",
    "        height = bar.get_height()\n",
    "        ax4.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'${val:,.0f}',\n",
    "                ha='center', va='bottom' if val > 0 else 'top',\n",
    "                fontweight='bold', fontsize=11)\n",
    "    \n",
    "    ax4.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax4.set_xlabel('Prediction Accuracy (%)', fontweight='bold')\n",
    "    ax4.set_ylabel('Prediction Advantage ($)', fontweight='bold')\n",
    "    ax4.set_title('Dollar Advantage of Predictions', fontweight='bold')\n",
    "    ax4.grid(True, alpha=0.3, axis='y')\n",
    "    ax4.set_xticks(SYNTHETIC_ACCURACIES)\n",
    "    \n",
    "    # Plot 5: Prediction Advantage (%)\n",
    "    ax5 = axes[1, 1]\n",
    "    \n",
    "    pct_advantage = (best_df['advantage'] / best_df['best_baseline']) * 100\n",
    "    bars = ax5.bar(best_df['accuracy'], pct_advantage,\n",
    "                   color=colors, alpha=0.8, edgecolor='black', linewidth=1.5)\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, val in zip(bars, pct_advantage):\n",
    "        height = bar.get_height()\n",
    "        ax5.text(bar.get_x() + bar.get_width()/2., height,\n",
    "                f'{val:+.1f}%',\n",
    "                ha='center', va='bottom' if val > 0 else 'top',\n",
    "                fontweight='bold', fontsize=11)\n",
    "    \n",
    "    ax5.axhline(y=0, color='black', linestyle='-', linewidth=1)\n",
    "    ax5.set_xlabel('Prediction Accuracy (%)', fontweight='bold')\n",
    "    ax5.set_ylabel('Prediction Advantage (%)', fontweight='bold')\n",
    "    ax5.set_title('Percentage Improvement with Predictions', fontweight='bold')\n",
    "    ax5.grid(True, alpha=0.3, axis='y')\n",
    "    ax5.set_xticks(SYNTHETIC_ACCURACIES)\n",
    "    \n",
    "    # Plot 6: Summary Table\n",
    "    ax6 = axes[1, 2]\n",
    "    ax6.axis('off')\n",
    "    \n",
    "    # Create summary data\n",
    "    table_data = []\n",
    "    for _, row in best_df.iterrows():\n",
    "        pct = ((row['best_prediction'] - row['best_baseline']) / row['best_baseline']) * 100\n",
    "        table_data.append([\n",
    "            f\"{row['accuracy']}%\",\n",
    "            f\"${row['best_baseline']:,.0f}\",\n",
    "            f\"${row['best_prediction']:,.0f}\",\n",
    "            f\"${row['advantage']:+,.0f}\",\n",
    "            f\"{pct:+.1f}%\"\n",
    "        ])\n",
    "    \n",
    "    table = ax6.table(cellText=table_data,\n",
    "                     colLabels=['Accuracy', 'Best\\nBaseline', 'Best\\nPrediction', \n",
    "                               'Advantage\\n($)', 'Advantage\\n(%)'],\n",
    "                     cellLoc='center',\n",
    "                     loc='center',\n",
    "                     colWidths=[0.15, 0.20, 0.20, 0.20, 0.15])\n",
    "    \n",
    "    table.auto_set_font_size(False)\n",
    "    table.set_fontsize(10)\n",
    "    table.scale(1, 3)\n",
    "    \n",
    "    # Style header\n",
    "    for i in range(5):\n",
    "        table[(0, i)].set_facecolor('#2c3e50')\n",
    "        table[(0, i)].set_text_props(weight='bold', color='white')\n",
    "    \n",
    "    # Style rows with accuracy colors\n",
    "    for i, acc in enumerate(SYNTHETIC_ACCURACIES, 1):\n",
    "        for j in range(5):\n",
    "            table[(i, j)].set_facecolor(ACCURACY_COLORS[acc])\n",
    "            table[(i, j)].set_alpha(0.3)\n",
    "    \n",
    "    ax6.set_title('Summary Table', fontsize=13, fontweight='bold', pad=20)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    # Save figure\n",
    "    output_path = f'{VOLUME_PATH}/synthetic_accuracy_comparison_{COMMODITY}.png'\n",
    "    plt.savefig(output_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"\\n‚úì Saved: {output_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Save data table\n",
    "    csv_path = f'{VOLUME_PATH}/synthetic_accuracy_comparison_{COMMODITY}.csv'\n",
    "    best_df.to_csv(csv_path, index=False)\n",
    "    print(f\"‚úì Saved: {csv_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 2: Monotonicity Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MONOTONICITY VALIDATION\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nChecking if performance improves monotonically with accuracy...\")\n",
    "print(\"(This should be TRUE for prediction strategies if logic is correct)\\n\")\n",
    "\n",
    "for COMMODITY in all_results.keys():\n",
    "    if len(all_results[COMMODITY]) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"{COMMODITY.upper()}\")\n",
    "    print(f\"{'‚îÄ'*80}\")\n",
    "    \n",
    "    commodity_results = all_results[COMMODITY]\n",
    "    \n",
    "    # Check each prediction strategy\n",
    "    for strategy in PREDICTION_STRATEGIES:\n",
    "        earnings_by_acc = {}\n",
    "        \n",
    "        for accuracy in sorted(commodity_results.keys()):\n",
    "            summary_df = commodity_results[accuracy]['summary']\n",
    "            strat_row = summary_df[summary_df['strategy'] == strategy]\n",
    "            \n",
    "            if len(strat_row) > 0:\n",
    "                earnings_by_acc[accuracy] = strat_row['net_earnings'].iloc[0]\n",
    "        \n",
    "        if len(earnings_by_acc) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Check monotonicity\n",
    "        accuracies = sorted(earnings_by_acc.keys())\n",
    "        earnings = [earnings_by_acc[acc] for acc in accuracies]\n",
    "        \n",
    "        is_monotonic = all(earnings[i] <= earnings[i+1] for i in range(len(earnings)-1))\n",
    "        \n",
    "        print(f\"\\n  {strategy}:\")\n",
    "        for acc in accuracies:\n",
    "            print(f\"    {acc}%: ${earnings_by_acc[acc]:,.2f}\")\n",
    "        \n",
    "        if is_monotonic:\n",
    "            print(f\"    ‚úì MONOTONIC: Performance improves with accuracy\")\n",
    "        else:\n",
    "            print(f\"    ‚úó NOT MONOTONIC: Performance does NOT consistently improve\")\n",
    "            print(f\"    ‚ö†Ô∏è  WARNING: This may indicate a logic issue!\")\n",
    "        \n",
    "        # Calculate correlation\n",
    "        if len(accuracies) >= 3:\n",
    "            corr, p_value = stats.pearsonr(accuracies, earnings)\n",
    "            print(f\"    Correlation: {corr:.3f} (p={p_value:.4f})\")\n",
    "            \n",
    "            if corr > 0.9 and p_value < 0.05:\n",
    "                print(f\"    ‚úì Strong positive correlation (expected)\")\n",
    "            elif corr < 0.5:\n",
    "                print(f\"    ‚ö†Ô∏è  Weak correlation - predictions may not be used effectively\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 3: 90% Accuracy Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"90% ACCURACY VALIDATION TEST\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nCRITICAL CHECK: At 90% accuracy, prediction strategies MUST beat baselines.\")\n",
    "print(\"If not, there's a bug in the trading logic.\\n\")\n",
    "\n",
    "validation_results = []\n",
    "\n",
    "for COMMODITY in all_results.keys():\n",
    "    if len(all_results[COMMODITY]) == 0 or 90 not in all_results[COMMODITY]:\n",
    "        print(f\"\\n‚ö†Ô∏è  No 90% accuracy results for {COMMODITY.upper()}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"{COMMODITY.upper()} - 90% ACCURACY\")\n",
    "    print(f\"{'‚îÄ'*80}\")\n",
    "    \n",
    "    summary_df = all_results[COMMODITY][90]['summary']\n",
    "    \n",
    "    # Get best baseline\n",
    "    baseline_df = summary_df[summary_df['strategy'].isin(BASELINE_STRATEGIES)]\n",
    "    best_baseline = baseline_df.loc[baseline_df['net_earnings'].idxmax()]\n",
    "    \n",
    "    print(f\"\\nBest Baseline: {best_baseline['strategy']}\")\n",
    "    print(f\"  Net Earnings: ${best_baseline['net_earnings']:,.2f}\")\n",
    "    \n",
    "    print(f\"\\nPrediction Strategies:\")\n",
    "    \n",
    "    pred_df = summary_df[summary_df['strategy'].isin(PREDICTION_STRATEGIES)]\n",
    "    \n",
    "    all_pass = True\n",
    "    \n",
    "    for _, pred_row in pred_df.iterrows():\n",
    "        advantage = pred_row['net_earnings'] - best_baseline['net_earnings']\n",
    "        pct_advantage = (advantage / best_baseline['net_earnings']) * 100\n",
    "        \n",
    "        beats_baseline = advantage > 0\n",
    "        \n",
    "        status = \"‚úì\" if beats_baseline else \"‚úó\"\n",
    "        \n",
    "        print(f\"\\n  {status} {pred_row['strategy']}:\")\n",
    "        print(f\"      Net Earnings: ${pred_row['net_earnings']:,.2f}\")\n",
    "        print(f\"      Advantage: ${advantage:+,.2f} ({pct_advantage:+.1f}%)\")\n",
    "        \n",
    "        if not beats_baseline:\n",
    "            all_pass = False\n",
    "            print(f\"      ‚ö†Ô∏è  FAILS: Does not beat best baseline!\")\n",
    "        else:\n",
    "            if pct_advantage > 10:\n",
    "                print(f\"      ‚úì STRONG: {pct_advantage:.1f}% improvement\")\n",
    "            elif pct_advantage > 5:\n",
    "                print(f\"      ‚úì MODERATE: {pct_advantage:.1f}% improvement\")\n",
    "            else:\n",
    "                print(f\"      ‚ö†Ô∏è  WEAK: Only {pct_advantage:.1f}% improvement\")\n",
    "        \n",
    "        validation_results.append({\n",
    "            'commodity': COMMODITY,\n",
    "            'strategy': pred_row['strategy'],\n",
    "            'net_earnings': pred_row['net_earnings'],\n",
    "            'baseline_earnings': best_baseline['net_earnings'],\n",
    "            'advantage': advantage,\n",
    "            'pct_advantage': pct_advantage,\n",
    "            'beats_baseline': beats_baseline\n",
    "        })\n",
    "    \n",
    "    print(f\"\\n{'‚îÄ'*40}\")\n",
    "    if all_pass:\n",
    "        print(f\"‚úì PASS: All prediction strategies beat baseline at 90% accuracy\")\n",
    "    else:\n",
    "        print(f\"‚úó FAIL: Some prediction strategies don't beat baseline!\")\n",
    "        print(f\"‚ö†Ô∏è  CRITICAL: This indicates a bug in the trading logic.\")\n",
    "\n",
    "# Summary table\n",
    "if len(validation_results) > 0:\n",
    "    validation_df = pd.DataFrame(validation_results)\n",
    "    \n",
    "    print(f\"\\n\\n{'='*80}\")\n",
    "    print(\"VALIDATION SUMMARY\")\n",
    "    print(f\"{'='*80}\\n\")\n",
    "    \n",
    "    pass_count = validation_df['beats_baseline'].sum()\n",
    "    total_count = len(validation_df)\n",
    "    pass_rate = (pass_count / total_count) * 100\n",
    "    \n",
    "    print(f\"Results: {pass_count}/{total_count} prediction strategies beat baseline ({pass_rate:.0f}%)\")\n",
    "    \n",
    "    if pass_rate == 100:\n",
    "        print(f\"\\n‚úì‚úì‚úì EXCELLENT: All prediction strategies work as expected!\")\n",
    "    elif pass_rate >= 80:\n",
    "        print(f\"\\n‚úì GOOD: Most prediction strategies work, but investigate failures\")\n",
    "    elif pass_rate >= 50:\n",
    "        print(f\"\\n‚ö†Ô∏è  CONCERN: Many prediction strategies fail - review logic\")\n",
    "    else:\n",
    "        print(f\"\\n‚úó‚úó‚úó CRITICAL: Trading logic appears broken - debug required!\")\n",
    "    \n",
    "    # Save validation results\n",
    "    val_csv = f'{VOLUME_PATH}/validation_90pct_accuracy.csv'\n",
    "    validation_df.to_csv(val_csv, index=False)\n",
    "    print(f\"\\n‚úì Saved validation results: {val_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 4: Accuracy Threshold Identification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"ACCURACY THRESHOLD ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\nAt what accuracy do predictions become valuable?\\n\")\n",
    "\n",
    "for COMMODITY in all_results.keys():\n",
    "    if len(all_results[COMMODITY]) == 0:\n",
    "        continue\n",
    "    \n",
    "    print(f\"\\n{'‚îÄ'*80}\")\n",
    "    print(f\"{COMMODITY.upper()}\")\n",
    "    print(f\"{'‚îÄ'*80}\")\n",
    "    \n",
    "    commodity_results = all_results[COMMODITY]\n",
    "    \n",
    "    # For each prediction strategy, find break-even accuracy\n",
    "    for strategy in PREDICTION_STRATEGIES:\n",
    "        print(f\"\\n  {strategy}:\")\n",
    "        \n",
    "        threshold_found = None\n",
    "        \n",
    "        for accuracy in sorted(commodity_results.keys()):\n",
    "            summary_df = commodity_results[accuracy]['summary']\n",
    "            \n",
    "            # Get strategy earnings\n",
    "            strat_row = summary_df[summary_df['strategy'] == strategy]\n",
    "            if len(strat_row) == 0:\n",
    "                continue\n",
    "            \n",
    "            strat_earnings = strat_row['net_earnings'].iloc[0]\n",
    "            \n",
    "            # Get best baseline\n",
    "            baseline_df = summary_df[summary_df['strategy'].isin(BASELINE_STRATEGIES)]\n",
    "            best_baseline_earnings = baseline_df['net_earnings'].max()\n",
    "            \n",
    "            beats_baseline = strat_earnings > best_baseline_earnings\n",
    "            advantage = strat_earnings - best_baseline_earnings\n",
    "            \n",
    "            print(f\"    {accuracy}%: ${strat_earnings:,.0f} (baseline: ${best_baseline_earnings:,.0f}) ‚Üí \"\n",
    "                  f\"{'+' if beats_baseline else '-'}${abs(advantage):,.0f}\")\n",
    "            \n",
    "            if beats_baseline and threshold_found is None:\n",
    "                threshold_found = accuracy\n",
    "        \n",
    "        if threshold_found:\n",
    "            print(f\"    ‚úì Threshold: {threshold_found}% (first accuracy where predictions beat baseline)\")\n",
    "        else:\n",
    "            print(f\"    ‚úó No threshold found (predictions never beat baseline in tested range)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis 5: Cross-Commodity Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CROSS-COMMODITY COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Create comparison table\n",
    "comparison_data = []\n",
    "\n",
    "for COMMODITY in all_results.keys():\n",
    "    commodity_results = all_results[COMMODITY]\n",
    "    \n",
    "    for accuracy in sorted(commodity_results.keys()):\n",
    "        summary_df = commodity_results[accuracy]['summary']\n",
    "        \n",
    "        baseline_df = summary_df[summary_df['strategy'].isin(BASELINE_STRATEGIES)]\n",
    "        pred_df = summary_df[summary_df['strategy'].isin(PREDICTION_STRATEGIES)]\n",
    "        \n",
    "        best_baseline = baseline_df['net_earnings'].max() if len(baseline_df) > 0 else 0\n",
    "        best_prediction = pred_df['net_earnings'].max() if len(pred_df) > 0 else 0\n",
    "        \n",
    "        comparison_data.append({\n",
    "            'commodity': COMMODITY,\n",
    "            'accuracy': accuracy,\n",
    "            'best_baseline': best_baseline,\n",
    "            'best_prediction': best_prediction,\n",
    "            'advantage': best_prediction - best_baseline,\n",
    "            'pct_advantage': ((best_prediction - best_baseline) / best_baseline * 100) if best_baseline > 0 else 0\n",
    "        })\n",
    "\n",
    "if len(comparison_data) > 0:\n",
    "    comparison_df = pd.DataFrame(comparison_data)\n",
    "    \n",
    "    # Pivot for easier viewing\n",
    "    pivot_pct = comparison_df.pivot(index='commodity', columns='accuracy', values='pct_advantage')\n",
    "    \n",
    "    print(\"\\nPercentage Advantage of Predictions by Commodity and Accuracy:\\n\")\n",
    "    print(pivot_pct.to_string())\n",
    "    \n",
    "    # Visualization\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "    \n",
    "    # Plot 1: Dollar advantage\n",
    "    ax1 = axes[0]\n",
    "    for commodity in comparison_df['commodity'].unique():\n",
    "        comm_data = comparison_df[comparison_df['commodity'] == commodity]\n",
    "        ax1.plot(comm_data['accuracy'], comm_data['advantage'],\n",
    "                marker='o', linewidth=2.5, label=commodity.title())\n",
    "    \n",
    "    ax1.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    ax1.set_xlabel('Prediction Accuracy (%)', fontweight='bold', fontsize=12)\n",
    "    ax1.set_ylabel('Dollar Advantage ($)', fontweight='bold', fontsize=12)\n",
    "    ax1.set_title('Prediction Advantage by Commodity', fontweight='bold', fontsize=14)\n",
    "    ax1.legend(fontsize=11)\n",
    "    ax1.grid(True, alpha=0.3)\n",
    "    ax1.set_xticks(SYNTHETIC_ACCURACIES)\n",
    "    \n",
    "    # Plot 2: Percentage advantage\n",
    "    ax2 = axes[1]\n",
    "    for commodity in comparison_df['commodity'].unique():\n",
    "        comm_data = comparison_df[comparison_df['commodity'] == commodity]\n",
    "        ax2.plot(comm_data['accuracy'], comm_data['pct_advantage'],\n",
    "                marker='o', linewidth=2.5, label=commodity.title())\n",
    "    \n",
    "    ax2.axhline(y=0, color='black', linestyle='--', linewidth=1)\n",
    "    ax2.set_xlabel('Prediction Accuracy (%)', fontweight='bold', fontsize=12)\n",
    "    ax2.set_ylabel('Percentage Advantage (%)', fontweight='bold', fontsize=12)\n",
    "    ax2.set_title('Percentage Improvement by Commodity', fontweight='bold', fontsize=14)\n",
    "    ax2.legend(fontsize=11)\n",
    "    ax2.grid(True, alpha=0.3)\n",
    "    ax2.set_xticks(SYNTHETIC_ACCURACIES)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    \n",
    "    cross_path = f'{VOLUME_PATH}/cross_commodity_accuracy_comparison.png'\n",
    "    plt.savefig(cross_path, dpi=300, bbox_inches='tight', facecolor='white')\n",
    "    print(f\"\\n‚úì Saved: {cross_path}\")\n",
    "    \n",
    "    plt.show()\n",
    "    plt.close()\n",
    "    \n",
    "    # Save comparison table\n",
    "    cross_csv = f'{VOLUME_PATH}/cross_commodity_accuracy_comparison.csv'\n",
    "    comparison_df.to_csv(cross_csv, index=False)\n",
    "    print(f\"‚úì Saved: {cross_csv}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SYNTHETIC ACCURACY ANALYSIS - FINAL SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nüìä ANALYSIS COMPLETE\")\n",
    "print(\"\\nKey Questions Answered:\")\n",
    "print(\"  1. ‚úì Performance vs Accuracy curves generated\")\n",
    "print(\"  2. ‚úì Monotonicity validated (should improve with accuracy)\")\n",
    "print(\"  3. ‚úì 90% accuracy validation performed (critical test)\")\n",
    "print(\"  4. ‚úì Accuracy threshold identified (where predictions become valuable)\")\n",
    "print(\"  5. ‚úì Cross-commodity comparison completed\")\n",
    "\n",
    "print(\"\\nüìÅ Outputs Saved:\")\n",
    "print(f\"  ‚Ä¢ Accuracy comparison charts (per commodity)\")\n",
    "print(f\"  ‚Ä¢ Validation results (90% accuracy test)\")\n",
    "print(f\"  ‚Ä¢ Cross-commodity comparison\")\n",
    "print(f\"  ‚Ä¢ CSV data tables\")\n",
    "\n",
    "print(\"\\n‚ö†Ô∏è  CRITICAL VALIDATION:\")\n",
    "print(\"  If 90% accuracy predictions DON'T show advantage:\")\n",
    "print(\"    ‚Üí Trading logic has bugs\")\n",
    "print(\"    ‚Üí Review strategy implementations\")\n",
    "print(\"    ‚Üí Check cost assumptions\")\n",
    "print(\"    ‚Üí Verify data isn't leaking future information\")\n",
    "\n",
    "print(\"\\n‚úì Notebook 11 Complete\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}