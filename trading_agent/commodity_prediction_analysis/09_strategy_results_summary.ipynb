{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "dba73c95-2b5e-4c94-aa13-06759384c339",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_setup_and_config\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3f28f1e7-1af1-4f2a-a37d-c94a8b38778b",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n================================================================================\nGENERATING REPORTS: COFFEE\n================================================================================\n\nDiscovering model versions...\n✓ Found 16 model versions\n\n--------------------------------------------------------------------------------\nMODEL: random_walk_v1_test\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - random_walk_v1_test\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_random_walk_v1_test.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: arima_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - arima_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_arima_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: sarimax_auto_weather_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - sarimax_auto_weather_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_sarimax_auto_weather_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: xgboost_weather_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - xgboost_weather_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_xgboost_weather_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: xgboost\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - xgboost\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_xgboost.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: arima_111_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - arima_111_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_arima_111_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: synthetic_acc70\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - synthetic_acc70\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/sensitivity_results_coffee_synthetic_acc70.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: sarimax_weather_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - sarimax_weather_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_sarimax_weather_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: prophet_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - prophet_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_prophet_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: synthetic_acc80\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - synthetic_acc80\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/sensitivity_results_coffee_synthetic_acc80.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: naive_baseline\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - naive_baseline\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_naive_baseline.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: random_walk_baseline\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - random_walk_baseline\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_random_walk_baseline.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: synthetic_acc60\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - synthetic_acc60\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/sensitivity_results_coffee_synthetic_acc60.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: random_walk_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - random_walk_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_random_walk_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: naive\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - naive\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_coffee_naive.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: synthetic_acc90\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for coffee - synthetic_acc90\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/sensitivity_results_coffee_synthetic_acc90.pkl'\n\n================================================================================\n✓ COFFEE COMPLETE\n================================================================================\n\n================================================================================\nGENERATING REPORTS: SUGAR\n================================================================================\n\nDiscovering model versions...\n✓ Found 9 model versions\n\n--------------------------------------------------------------------------------\nMODEL: sarimax_auto_weather_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for sugar - sarimax_auto_weather_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_sugar_sarimax_auto_weather_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: xgboost_weather_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for sugar - xgboost_weather_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_sugar_xgboost_weather_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: arima_111_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for sugar - arima_111_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_sugar_arima_111_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: synthetic_acc70\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for sugar - synthetic_acc70\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/sensitivity_results_sugar_synthetic_acc70.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: prophet_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for sugar - prophet_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_sugar_prophet_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: synthetic_acc80\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for sugar - synthetic_acc80\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/sensitivity_results_sugar_synthetic_acc80.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: random_walk_v1\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for sugar - random_walk_v1\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/feature_analysis_sugar_random_walk_v1.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: synthetic_acc60\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for sugar - synthetic_acc60\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/sensitivity_results_sugar_synthetic_acc60.pkl'\n\n--------------------------------------------------------------------------------\nMODEL: synthetic_acc90\n--------------------------------------------------------------------------------\n\nLoading results...\n⚠️  Missing file for sugar - synthetic_acc90\n   [Errno 2] No such file or directory: '/Volumes/commodity/trading_agent/files/sensitivity_results_sugar_synthetic_acc90.pkl'\n\n================================================================================\n✓ SUGAR COMPLETE\n================================================================================\n\n================================================================================\nGENERATING CROSS-MODEL AND CROSS-COMMODITY SUMMARY\n================================================================================\n\n⚠️  No summaries generated\n\n================================================================================\nVISUALIZATION AND REPORTING COMPLETE\n================================================================================\n\nAll reports and dashboards saved to: /Volumes/commodity/trading_agent/files\n\n✓ Block 08 complete\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\nCOMMODITY CONFIGURATIONS\n================================================================================\n\nCOFFEE:\n  Harvest volume: 50 tons/year\n  Harvest windows: [(5, 9)]\n  Total harvest weeks: 21\n  Weekly harvest rate: 2.38 tons/week\n\n  Costs (percentage-based):\n    Storage: 0.025% of value per day\n    Transaction: 0.25% of sale value\n    Max holding: 365 days from harvest start\n\n  Example at $150/ton:\n    Transaction cost (full harvest): $18.75\n    Storage per day (full harvest): $1.88\n    Storage per month (full harvest): $56.25\n    Storage for 6 months: $337.50\n\nReal Prediction Data:\n  ✓ Real prediction data found in table: commodity.forecast.distributions\n  Model versions available: 12\n    - arima_111_v1\n    - arima_v1\n    - naive\n    - naive_baseline\n    - prophet_v1\n    - random_walk_baseline\n    - random_walk_v1\n    - random_walk_v1_test\n    - sarimax_auto_weather_v1\n    - sarimax_weather_v1\n    - xgboost\n    - xgboost_weather_v1\n\nSUGAR:\n  Harvest volume: 50 tons/year\n  Harvest windows: [(10, 12)]\n  Total harvest weeks: 12\n  Weekly harvest rate: 4.17 tons/week\n\n  Costs (percentage-based):\n    Storage: 0.025% of value per day\n    Transaction: 0.25% of sale value\n    Max holding: 365 days from harvest start\n\n  Example at $400/ton:\n    Transaction cost (full harvest): $50.00\n    Storage per day (full harvest): $5.00\n    Storage per month (full harvest): $150.00\n    Storage for 6 months: $900.00\n\nReal Prediction Data:\n  ✓ Real prediction data found in table: commodity.forecast.distributions\n  Model versions available: 5\n    - arima_111_v1\n    - prophet_v1\n    - random_walk_v1\n    - sarimax_auto_weather_v1\n    - xgboost_weather_v1\n\n================================================================================\nSTRATEGY PARAMETERS (SHARED)\n================================================================================\n\nBaseline Strategy Parameters:\n{\n  \"equal_batch\": {\n    \"batch_size\": 0.25,\n    \"frequency_days\": 30\n  },\n  \"price_threshold\": {\n    \"threshold_pct\": 0.05\n  },\n  \"moving_average\": {\n    \"ma_period\": 30\n  }\n}\n\nPrediction Strategy Parameters:\n{\n  \"consensus\": {\n    \"consensus_threshold\": 0.7,\n    \"min_return\": 0.03,\n    \"evaluation_day\": 14\n  },\n  \"expected_value\": {\n    \"min_ev_improvement\": 50,\n    \"baseline_batch\": 0.15,\n    \"baseline_frequency\": 10\n  },\n  \"risk_adjusted\": {\n    \"min_return\": 0.03,\n    \"max_uncertainty\": 0.35,\n    \"consensus_threshold\": 0.6,\n    \"evaluation_day\": 14\n  }\n}\n\n================================================================================\nANALYSIS CONFIGURATION\n================================================================================\n{\n  \"backtest_start_date\": \"2018-01-01\",\n  \"backtest_end_date\": \"2025-09-24\",\n  \"bootstrap_iterations\": 1000,\n  \"confidence_level\": 0.95,\n  \"random_seed\": 42,\n  \"prediction_runs\": 500,\n  \"forecast_horizon\": 14\n}\n\nForecast table: commodity.forecast.distributions\nOutput schema: commodity.trading_agent\nVolume path: /Volumes/commodity/trading_agent/files\n\n================================================================================\nCOMMODITIES TO ANALYZE\n================================================================================\nWill run analysis for: ['coffee', 'sugar']\n\n✓ Configuration complete\n"
     ]
    }
   ],
   "source": [
    "# NOTEBOOK 09: VISUALIZATION AND REPORTING (MULTI-MODEL)\n",
    "# ============================================================================\n",
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # Final Report and Dashboard - All Commodities and Model Versions\n",
    "# MAGIC \n",
    "# MAGIC Creates comprehensive reports and visualizations for each commodity and model version\n",
    "# MAGIC plus cross-model and cross-commodity comparisons.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Generate Individual Commodity and Model Reports\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Store summaries for cross-commodity and cross-model comparison\n",
    "all_summaries = []\n",
    "\n",
    "# Loop through all commodities\n",
    "for CURRENT_COMMODITY in COMMODITY_CONFIGS.keys():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"GENERATING REPORTS: {CURRENT_COMMODITY.upper()}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Discover all model versions for this commodity\n",
    "    print(f\"\\nDiscovering model versions...\")\n",
    "    \n",
    "    synthetic_versions = []\n",
    "    try:\n",
    "        DATA_PATHS = get_data_paths(CURRENT_COMMODITY)\n",
    "        synthetic_df = spark.table(DATA_PATHS['predictions']).select(\"model_version\").distinct()\n",
    "        synthetic_versions = [row.model_version for row in synthetic_df.collect()]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    real_versions = []\n",
    "    try:\n",
    "        real_versions = get_model_versions(CURRENT_COMMODITY)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    all_model_versions = list(set(synthetic_versions + real_versions))\n",
    "    \n",
    "    if len(all_model_versions) == 0:\n",
    "        print(f\"⚠️  No model versions found for {CURRENT_COMMODITY}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"✓ Found {len(all_model_versions)} model versions\")\n",
    "    \n",
    "    # Loop through each model version\n",
    "    for MODEL_VERSION in all_model_versions:\n",
    "        print(f\"\\n{'-' * 80}\")\n",
    "        print(f\"MODEL: {MODEL_VERSION}\")\n",
    "        print(f\"{'-' * 80}\")\n",
    "        \n",
    "        MODEL_DATA_PATHS = get_data_paths(CURRENT_COMMODITY, MODEL_VERSION)\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # Load All Results\n",
    "        # ----------------------------------------------------------------------\n",
    "        print(f\"\\nLoading results...\")\n",
    "        \n",
    "        try:\n",
    "            with open(MODEL_DATA_PATHS['results_detailed'], 'rb') as f:\n",
    "                results_detailed = pickle.load(f)\n",
    "            \n",
    "            with open(MODEL_DATA_PATHS['statistical_results'], 'rb') as f:\n",
    "                stat_results = pickle.load(f)\n",
    "            \n",
    "            with open(MODEL_DATA_PATHS['feature_analysis'], 'rb') as f:\n",
    "                feature_results = pickle.load(f)\n",
    "            \n",
    "            with open(MODEL_DATA_PATHS['sensitivity_results'], 'rb') as f:\n",
    "                sensitivity_results = pickle.load(f)\n",
    "            \n",
    "            results_df = spark.table(MODEL_DATA_PATHS['results']).toPandas()\n",
    "            \n",
    "            print(f\"✓ Loaded all analysis results\")\n",
    "            \n",
    "        except FileNotFoundError as e:\n",
    "            print(f\"⚠️  Missing file for {CURRENT_COMMODITY} - {MODEL_VERSION}\")\n",
    "            print(f\"   {e}\")\n",
    "            continue\n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Error loading data: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # Executive Summary\n",
    "        # ----------------------------------------------------------------------\n",
    "        print(f\"\\nGenerating executive summary...\")\n",
    "        \n",
    "        # Best performers\n",
    "        best_overall = results_df.loc[results_df['net_earnings'].idxmax()]\n",
    "        \n",
    "        baseline_results = results_df[results_df['type'] == 'baseline']\n",
    "        prediction_results = results_df[results_df['type'] == 'prediction']\n",
    "        \n",
    "        best_baseline = baseline_results.loc[baseline_results['net_earnings'].idxmax()] if len(baseline_results) > 0 else None\n",
    "        best_prediction = prediction_results.loc[prediction_results['net_earnings'].idxmax()] if len(prediction_results) > 0 else None\n",
    "        \n",
    "        # Calculate advantage\n",
    "        if best_baseline is not None and best_prediction is not None:\n",
    "            earnings_diff = best_prediction['net_earnings'] - best_baseline['net_earnings']\n",
    "            pct_diff = (earnings_diff / abs(best_baseline['net_earnings'])) * 100 if best_baseline['net_earnings'] != 0 else 0\n",
    "        else:\n",
    "            earnings_diff = 0\n",
    "            pct_diff = 0\n",
    "        \n",
    "        # Summary statistics\n",
    "        summary = {\n",
    "            'commodity': CURRENT_COMMODITY,\n",
    "            'model_version': MODEL_VERSION,\n",
    "            'source_type': 'SYNTHETIC' if MODEL_VERSION.startswith('synthetic_') else 'REAL',\n",
    "            'best_overall_strategy': best_overall['strategy'],\n",
    "            'best_overall_earnings': best_overall['net_earnings'],\n",
    "            'best_baseline_strategy': best_baseline['strategy'] if best_baseline is not None else None,\n",
    "            'best_baseline_earnings': best_baseline['net_earnings'] if best_baseline is not None else None,\n",
    "            'best_prediction_strategy': best_prediction['strategy'] if best_prediction is not None else None,\n",
    "            'best_prediction_earnings': best_prediction['net_earnings'] if best_prediction is not None else None,\n",
    "            'prediction_advantage_dollars': earnings_diff,\n",
    "            'prediction_advantage_pct': pct_diff,\n",
    "            'n_strategies_tested': len(results_df),\n",
    "            'statistical_significance': stat_results.get('comparisons', pd.DataFrame()).get('significant', pd.Series()).any() if 'comparisons' in stat_results else False\n",
    "        }\n",
    "        \n",
    "        all_summaries.append(summary)\n",
    "        \n",
    "        print(f\"✓ Executive summary created\")\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # Create Summary Report\n",
    "        # ----------------------------------------------------------------------\n",
    "        print(f\"\\nCreating summary report...\")\n",
    "        \n",
    "        report_lines = []\n",
    "        report_lines.append(\"=\" * 80)\n",
    "        report_lines.append(f\"TRADING STRATEGY ANALYSIS REPORT\")\n",
    "        report_lines.append(f\"Commodity: {CURRENT_COMMODITY.upper()}\")\n",
    "        report_lines.append(f\"Model: {MODEL_VERSION}\")\n",
    "        report_lines.append(f\"Generated: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "        report_lines.append(\"=\" * 80)\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        report_lines.append(\"EXECUTIVE SUMMARY\")\n",
    "        report_lines.append(\"-\" * 80)\n",
    "        report_lines.append(f\"Best Overall Strategy: {best_overall['strategy']}\")\n",
    "        report_lines.append(f\"  Net Earnings: ${best_overall['net_earnings']:,.2f}\")\n",
    "        report_lines.append(f\"  Total Revenue: ${best_overall['total_revenue']:,.2f}\")\n",
    "        report_lines.append(f\"  Total Costs: ${best_overall['total_costs']:,.2f}\")\n",
    "        report_lines.append(f\"  Number of Trades: {best_overall['n_trades']}\")\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        if best_baseline is not None:\n",
    "            report_lines.append(f\"Best Baseline Strategy: {best_baseline['strategy']}\")\n",
    "            report_lines.append(f\"  Net Earnings: ${best_baseline['net_earnings']:,.2f}\")\n",
    "            report_lines.append(\"\")\n",
    "        \n",
    "        if best_prediction is not None:\n",
    "            report_lines.append(f\"Best Prediction Strategy: {best_prediction['strategy']}\")\n",
    "            report_lines.append(f\"  Net Earnings: ${best_prediction['net_earnings']:,.2f}\")\n",
    "            report_lines.append(f\"  Advantage over Baseline: ${earnings_diff:+,.2f} ({pct_diff:+.1f}%)\")\n",
    "            report_lines.append(\"\")\n",
    "        \n",
    "        report_lines.append(\"STRATEGY COMPARISON\")\n",
    "        report_lines.append(\"-\" * 80)\n",
    "        for _, row in results_df.sort_values('net_earnings', ascending=False).iterrows():\n",
    "            report_lines.append(f\"{row['strategy']:30s} {row['type']:10s} ${row['net_earnings']:>12,.2f}\")\n",
    "        report_lines.append(\"\")\n",
    "        \n",
    "        if 'comparisons' in stat_results and stat_results['comparisons'] is not None and len(stat_results['comparisons']) > 0:\n",
    "            report_lines.append(\"STATISTICAL SIGNIFICANCE\")\n",
    "            report_lines.append(\"-\" * 80)\n",
    "            for _, row in stat_results['comparisons'].iterrows():\n",
    "                sig_marker = \"***\" if row['p_value'] < 0.001 else \"**\" if row['p_value'] < 0.01 else \"*\" if row['p_value'] < 0.05 else \"ns\"\n",
    "                report_lines.append(f\"{row['strategy']:30s} p={row['p_value']:.4f} {sig_marker:3s} d={row['cohens_d']:+.3f}\")\n",
    "            report_lines.append(\"\")\n",
    "        \n",
    "        if 'feature_importance' in feature_results:\n",
    "            report_lines.append(\"FEATURE IMPORTANCE\")\n",
    "            report_lines.append(\"-\" * 80)\n",
    "            for _, row in feature_results['feature_importance'].iterrows():\n",
    "                report_lines.append(f\"{row['feature']:30s} {row['importance']:.3f}\")\n",
    "            report_lines.append(\"\")\n",
    "        \n",
    "        report_lines.append(\"=\" * 80)\n",
    "        \n",
    "        report_text = \"\\n\".join(report_lines)\n",
    "        \n",
    "        # Save report\n",
    "        report_path = f'{VOLUME_PATH}/report_{CURRENT_COMMODITY}_{MODEL_VERSION}.txt'\n",
    "        with open(report_path, 'w') as f:\n",
    "            f.write(report_text)\n",
    "        \n",
    "        print(f\"✓ Saved: {report_path}\")\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # Create Dashboard Visualization\n",
    "        # ----------------------------------------------------------------------\n",
    "        print(f\"\\nCreating dashboard visualization...\")\n",
    "        \n",
    "        fig = plt.figure(figsize=(20, 12))\n",
    "        gs = fig.add_gridspec(3, 3, hspace=0.3, wspace=0.3)\n",
    "        \n",
    "        # 1. Strategy Earnings Comparison\n",
    "        ax1 = fig.add_subplot(gs[0, :2])\n",
    "        results_sorted = results_df.sort_values('net_earnings', ascending=False)\n",
    "        colors = ['orangered' if t == 'prediction' else 'steelblue' for t in results_sorted['type']]\n",
    "        ax1.barh(results_sorted['strategy'], results_sorted['net_earnings'], color=colors, alpha=0.7)\n",
    "        ax1.set_xlabel('Net Earnings ($)')\n",
    "        ax1.set_title(f'Strategy Performance - {CURRENT_COMMODITY.upper()} - {MODEL_VERSION}', fontweight='bold')\n",
    "        ax1.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # 2. Feature Importance\n",
    "        if 'feature_importance' in feature_results:\n",
    "            ax2 = fig.add_subplot(gs[0, 2])\n",
    "            feat_imp = feature_results['feature_importance'].head(6)\n",
    "            ax2.barh(feat_imp['feature'], feat_imp['importance'], color='forestgreen', alpha=0.7)\n",
    "            ax2.set_xlabel('Importance')\n",
    "            ax2.set_title('Top Features', fontweight='bold')\n",
    "            ax2.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # 3. Transaction Cost Sensitivity\n",
    "        if 'transaction_sensitivity' in sensitivity_results:\n",
    "            ax3 = fig.add_subplot(gs[1, 0])\n",
    "            trans_sens = sensitivity_results['transaction_sensitivity']\n",
    "            ax3.plot(trans_sens['cost_multiplier'], trans_sens['prediction_earnings'], \n",
    "                    marker='o', label='Prediction', color='orangered')\n",
    "            ax3.plot(trans_sens['cost_multiplier'], trans_sens['baseline_earnings'], \n",
    "                    marker='s', label='Baseline', color='steelblue')\n",
    "            ax3.set_xlabel('Cost Multiplier')\n",
    "            ax3.set_ylabel('Net Earnings ($)')\n",
    "            ax3.set_title('Transaction Cost Sensitivity', fontweight='bold')\n",
    "            ax3.legend()\n",
    "            ax3.grid(True, alpha=0.3)\n",
    "            ax3.axvline(x=1.0, color='black', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # 4. Storage Cost Sensitivity\n",
    "        if 'storage_sensitivity' in sensitivity_results:\n",
    "            ax4 = fig.add_subplot(gs[1, 1])\n",
    "            stor_sens = sensitivity_results['storage_sensitivity']\n",
    "            ax4.plot(stor_sens['cost_multiplier'], stor_sens['prediction_earnings'], \n",
    "                    marker='o', label='Prediction', color='orangered')\n",
    "            ax4.plot(stor_sens['cost_multiplier'], stor_sens['baseline_earnings'], \n",
    "                    marker='s', label='Baseline', color='steelblue')\n",
    "            ax4.set_xlabel('Cost Multiplier')\n",
    "            ax4.set_ylabel('Net Earnings ($)')\n",
    "            ax4.set_title('Storage Cost Sensitivity', fontweight='bold')\n",
    "            ax4.legend()\n",
    "            ax4.grid(True, alpha=0.3)\n",
    "            ax4.axvline(x=1.0, color='black', linestyle='--', alpha=0.5)\n",
    "        \n",
    "        # 5. Statistical Comparison\n",
    "        if 'comparisons' in stat_results and stat_results['comparisons'] is not None and len(stat_results['comparisons']) > 0:\n",
    "            ax5 = fig.add_subplot(gs[1, 2])\n",
    "            comp = stat_results['comparisons']\n",
    "            colors_sig = ['green' if s else 'gray' for s in comp['significant']]\n",
    "            ax5.barh(comp['strategy'], comp['total_earnings_diff'], color=colors_sig, alpha=0.7)\n",
    "            ax5.axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "            ax5.set_xlabel('Earnings Advantage ($)')\n",
    "            ax5.set_title('vs Best Baseline', fontweight='bold')\n",
    "            ax5.grid(True, alpha=0.3, axis='x')\n",
    "        \n",
    "        # 6. Summary Stats Table\n",
    "        ax6 = fig.add_subplot(gs[2, :])\n",
    "        ax6.axis('off')\n",
    "        \n",
    "        summary_text = f\"\"\"\n",
    "        SUMMARY STATISTICS\n",
    "        \n",
    "        Best Overall: {best_overall['strategy']} (${best_overall['net_earnings']:,.2f})\n",
    "        Best Baseline: {best_baseline['strategy'] if best_baseline is not None else 'N/A'}\n",
    "        Best Prediction: {best_prediction['strategy'] if best_prediction is not None else 'N/A'}\n",
    "        \n",
    "        Prediction Advantage: ${earnings_diff:+,.2f} ({pct_diff:+.1f}%)\n",
    "        Statistical Significance: {'YES' if summary['statistical_significance'] else 'NO'}\n",
    "        \"\"\"\n",
    "        \n",
    "        ax6.text(0.1, 0.5, summary_text, fontsize=12, verticalalignment='center', \n",
    "                family='monospace')\n",
    "        \n",
    "        plt.suptitle(f'Trading Strategy Analysis Dashboard\\n{CURRENT_COMMODITY.upper()} - {MODEL_VERSION}', \n",
    "                    fontsize=16, fontweight='bold', y=0.98)\n",
    "        \n",
    "        dashboard_path = f'{VOLUME_PATH}/dashboard_{CURRENT_COMMODITY}_{MODEL_VERSION}.png'\n",
    "        plt.savefig(dashboard_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ Saved: {dashboard_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        print(f\"\\n✓ Report complete for {MODEL_VERSION}\")\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"✓ {CURRENT_COMMODITY.upper()} COMPLETE\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Cross-Model and Cross-Commodity Summary\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"GENERATING CROSS-MODEL AND CROSS-COMMODITY SUMMARY\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "if len(all_summaries) > 0:\n",
    "    summary_df = pd.DataFrame(all_summaries)\n",
    "    \n",
    "    print(f\"\\nTotal combinations analyzed: {len(summary_df)}\")\n",
    "    print(f\"  Commodities: {summary_df['commodity'].nunique()}\")\n",
    "    print(f\"  Model versions: {summary_df['model_version'].nunique()}\")\n",
    "    \n",
    "    # Save summary\n",
    "    summary_csv = f'{VOLUME_PATH}/all_models_summary.csv'\n",
    "    summary_df.to_csv(summary_csv, index=False)\n",
    "    print(f\"\\n✓ Saved: {summary_csv}\")\n",
    "    \n",
    "    # Display key findings\n",
    "    print(\"\\nTOP PERFORMERS:\")\n",
    "    print(\"-\" * 80)\n",
    "    top_10 = summary_df.nlargest(10, 'best_prediction_earnings')\n",
    "    for _, row in top_10.iterrows():\n",
    "        print(f\"{row['commodity']:10s} {row['model_version']:25s} ${row['best_prediction_earnings']:>12,.2f}  ({row['prediction_advantage_pct']:+6.1f}%)\")\n",
    "    \n",
    "    print(\"\\n✓ All reports and visualizations complete\")\n",
    "else:\n",
    "    print(\"\\n⚠️  No summaries generated\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"VISUALIZATION AND REPORTING COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"\\nAll reports and dashboards saved to: {VOLUME_PATH}\")\n",
    "print(\"\\n✓ Block 08 complete\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "09_strategy_results_summary",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}