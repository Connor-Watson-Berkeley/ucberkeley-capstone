{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "d34312ec-7697-4e57-a974-e3193c61aca7",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./00_setup_and_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "f1cc0c27-125e-452e-8667-9ffb9a2fc9ea",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./03_strategy_implementations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e0cee354-97ef-4a84-be06-3407319983a9",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "%run ./04_backtesting_engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "60ef1a56-b635-4862-9902-ed3f61b819ec",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "# NOTEBOOK 08: SENSITIVITY ANALYSIS (MULTI-MODEL)\n",
    "# ============================================================================\n",
    "# Databricks notebook source\n",
    "# MAGIC %md\n",
    "# MAGIC # Sensitivity Analysis - All Commodities and Model Versions\n",
    "# MAGIC \n",
    "# MAGIC Tests how robust strategies are to parameter and cost changes.\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Sensitivity Analysis Functions\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "def run_sensitivity_consensus(prices, prediction_matrices, commodity_config):\n",
    "    \"\"\"Test sensitivity of Consensus strategy to parameter changes.\"\"\"\n",
    "    engine = BacktestEngine(prices, prediction_matrices, commodity_config)\n",
    "    results = []\n",
    "    \n",
    "    # Test different consensus thresholds and minimum returns\n",
    "    for cons_thresh in [0.60, 0.65, 0.70, 0.75, 0.80]:\n",
    "        for min_ret in [0.02, 0.03, 0.04, 0.05, 0.06]:\n",
    "            strategy = ConsensusStrategy(\n",
    "                consensus_threshold=cons_thresh, \n",
    "                min_return=min_ret, \n",
    "                evaluation_day=ANALYSIS_CONFIG['forecast_horizon']\n",
    "            )\n",
    "            backtest_result = engine.run(strategy)\n",
    "            metrics = calculate_metrics(backtest_result)\n",
    "            results.append({\n",
    "                'consensus_threshold': cons_thresh, \n",
    "                'min_return': min_ret, \n",
    "                **metrics\n",
    "            })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "def run_cost_sensitivity(prices, prediction_matrices, commodity_config, cost_type='transaction'):\n",
    "    \"\"\"Test sensitivity to transaction or storage cost changes (percentage-based).\"\"\"\n",
    "    results = []\n",
    "    \n",
    "    for multiplier in [0.5, 0.75, 1.0, 1.5, 2.0]:\n",
    "        config = commodity_config.copy()\n",
    "        \n",
    "        if cost_type == 'transaction':\n",
    "            config['transaction_cost_pct'] = commodity_config['transaction_cost_pct'] * multiplier\n",
    "        elif cost_type == 'storage':\n",
    "            config['storage_cost_pct_per_day'] = commodity_config['storage_cost_pct_per_day'] * multiplier\n",
    "        \n",
    "        engine = BacktestEngine(prices, prediction_matrices, config)\n",
    "        \n",
    "        # Run prediction strategy\n",
    "        pred_strategy = RiskAdjustedStrategy(**PREDICTION_PARAMS['risk_adjusted'])\n",
    "        pred_result = engine.run(pred_strategy)\n",
    "        pred_metrics = calculate_metrics(pred_result)\n",
    "        \n",
    "        # Run baseline strategy\n",
    "        baseline_strategy = MovingAverageStrategy(ma_period=BASELINE_PARAMS['moving_average']['ma_period'])\n",
    "        baseline_result = engine.run(baseline_strategy)\n",
    "        baseline_metrics = calculate_metrics(baseline_result)\n",
    "        \n",
    "        results.append({\n",
    "            'cost_multiplier': multiplier,\n",
    "            'prediction_earnings': pred_metrics['net_earnings'],\n",
    "            'baseline_earnings': baseline_metrics['net_earnings'],\n",
    "            'advantage': pred_metrics['net_earnings'] - baseline_metrics['net_earnings']\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results)\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# MAGIC %md\n",
    "# MAGIC ## Run Sensitivity Analysis for All Commodities and Models\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "# Loop through all commodities\n",
    "for CURRENT_COMMODITY in COMMODITY_CONFIGS.keys():\n",
    "    print(\"\\n\" + \"=\" * 80)\n",
    "    print(f\"SENSITIVITY ANALYSIS: {CURRENT_COMMODITY.upper()}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    CURRENT_CONFIG = COMMODITY_CONFIGS[CURRENT_COMMODITY]\n",
    "    \n",
    "    # Discover all model versions for this commodity\n",
    "    print(f\"\\nDiscovering model versions...\")\n",
    "    \n",
    "    synthetic_versions = []\n",
    "    try:\n",
    "        DATA_PATHS = get_data_paths(CURRENT_COMMODITY)\n",
    "        synthetic_df = spark.table(DATA_PATHS['predictions']).select(\"model_version\").distinct()\n",
    "        synthetic_versions = [row.model_version for row in synthetic_df.collect()]\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    real_versions = []\n",
    "    try:\n",
    "        real_versions = get_model_versions(CURRENT_COMMODITY)\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    all_model_versions = list(set(synthetic_versions + real_versions))\n",
    "    \n",
    "    if len(all_model_versions) == 0:\n",
    "        print(f\"⚠️  No model versions found for {CURRENT_COMMODITY}\")\n",
    "        continue\n",
    "    \n",
    "    print(f\"✓ Found {len(all_model_versions)} model versions\")\n",
    "    \n",
    "    # Loop through each model version\n",
    "    for MODEL_VERSION in all_model_versions:\n",
    "        print(f\"\\n{'-' * 80}\")\n",
    "        print(f\"MODEL: {MODEL_VERSION}\")\n",
    "        print(f\"{'-' * 80}\")\n",
    "        \n",
    "        MODEL_DATA_PATHS = get_data_paths(CURRENT_COMMODITY, MODEL_VERSION)\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # Load Data\n",
    "        # ----------------------------------------------------------------------\n",
    "        print(f\"\\nLoading prepared data...\")\n",
    "        \n",
    "        try:\n",
    "            prices = spark.table(get_data_paths(CURRENT_COMMODITY)['prices_prepared']).toPandas()\n",
    "            prices['date'] = pd.to_datetime(prices['date'])\n",
    "            \n",
    "            # Load prediction matrices for this model version\n",
    "            if MODEL_VERSION.startswith('synthetic_'):\n",
    "                matrices_path = MODEL_DATA_PATHS['prediction_matrices']\n",
    "            else:\n",
    "                matrices_path = MODEL_DATA_PATHS['prediction_matrices_real']\n",
    "            \n",
    "            with open(matrices_path, 'rb') as f:\n",
    "                prediction_matrices = pickle.load(f)\n",
    "            \n",
    "            print(f\"✓ Loaded {len(prices)} days of prices\")\n",
    "            print(f\"✓ Loaded {len(prediction_matrices)} prediction matrices\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"⚠️  Could not load data: {e}\")\n",
    "            continue\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # Consensus Strategy Parameter Sensitivity\n",
    "        # ----------------------------------------------------------------------\n",
    "        print(f\"\\nRunning Consensus strategy parameter sensitivity...\")\n",
    "        \n",
    "        consensus_sensitivity = run_sensitivity_consensus(prices, prediction_matrices, CURRENT_CONFIG)\n",
    "        \n",
    "        print(f\"✓ Tested {len(consensus_sensitivity)} parameter combinations\")\n",
    "        \n",
    "        # Find optimal parameters\n",
    "        best_params = consensus_sensitivity.loc[consensus_sensitivity['net_earnings'].idxmax()]\n",
    "        print(f\"\\nOptimal parameters:\")\n",
    "        print(f\"  Consensus threshold: {best_params['consensus_threshold']:.2f}\")\n",
    "        print(f\"  Minimum return: {best_params['min_return']:.2%}\")\n",
    "        print(f\"  Net earnings: ${best_params['net_earnings']:,.2f}\")\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # Transaction Cost Sensitivity\n",
    "        # ----------------------------------------------------------------------\n",
    "        print(f\"\\nRunning transaction cost sensitivity...\")\n",
    "        \n",
    "        transaction_sensitivity = run_cost_sensitivity(prices, prediction_matrices, CURRENT_CONFIG, cost_type='transaction')\n",
    "        \n",
    "        print(f\"✓ Tested {len(transaction_sensitivity)} cost scenarios\")\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # Storage Cost Sensitivity\n",
    "        # ----------------------------------------------------------------------\n",
    "        print(f\"\\nRunning storage cost sensitivity...\")\n",
    "        \n",
    "        storage_sensitivity = run_cost_sensitivity(prices, prediction_matrices, CURRENT_CONFIG, cost_type='storage')\n",
    "        \n",
    "        print(f\"✓ Tested {len(storage_sensitivity)} cost scenarios\")\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # Visualizations\n",
    "        # ----------------------------------------------------------------------\n",
    "        print(f\"\\nGenerating visualizations...\")\n",
    "        \n",
    "        # 1. Consensus parameter heatmap\n",
    "        fig, ax = plt.subplots(figsize=(10, 8))\n",
    "        \n",
    "        pivot_data = consensus_sensitivity.pivot(\n",
    "            index='min_return', \n",
    "            columns='consensus_threshold', \n",
    "            values='net_earnings'\n",
    "        )\n",
    "        \n",
    "        sns.heatmap(pivot_data, annot=True, fmt='.0f', cmap='RdYlGn', ax=ax, \n",
    "                   cbar_kws={'label': 'Net Earnings ($)'})\n",
    "        \n",
    "        ax.set_title(f'Consensus Strategy Parameter Sensitivity\\n{CURRENT_COMMODITY.upper()} - {MODEL_VERSION}', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        ax.set_xlabel('Consensus Threshold', fontsize=12)\n",
    "        ax.set_ylabel('Minimum Return', fontsize=12)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        heatmap_path = f'{VOLUME_PATH}/consensus_sensitivity_{CURRENT_COMMODITY}_{MODEL_VERSION}.png'\n",
    "        plt.savefig(heatmap_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ Saved: {heatmap_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Transaction cost sensitivity\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        ax.plot(transaction_sensitivity['cost_multiplier'], \n",
    "               transaction_sensitivity['prediction_earnings'], \n",
    "               marker='o', linewidth=2, label='Prediction Strategy', color='orangered')\n",
    "        ax.plot(transaction_sensitivity['cost_multiplier'], \n",
    "               transaction_sensitivity['baseline_earnings'], \n",
    "               marker='s', linewidth=2, label='Baseline Strategy', color='steelblue')\n",
    "        \n",
    "        ax.set_xlabel('Transaction Cost Multiplier', fontsize=12)\n",
    "        ax.set_ylabel('Net Earnings ($)', fontsize=12)\n",
    "        ax.set_title(f'Transaction Cost Sensitivity\\n{CURRENT_COMMODITY.upper()} - {MODEL_VERSION}', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.axvline(x=1.0, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Baseline Cost')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        trans_path = f'{VOLUME_PATH}/transaction_sensitivity_{CURRENT_COMMODITY}_{MODEL_VERSION}.png'\n",
    "        plt.savefig(trans_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ Saved: {trans_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Storage cost sensitivity\n",
    "        fig, ax = plt.subplots(figsize=(12, 6))\n",
    "        \n",
    "        ax.plot(storage_sensitivity['cost_multiplier'], \n",
    "               storage_sensitivity['prediction_earnings'], \n",
    "               marker='o', linewidth=2, label='Prediction Strategy', color='orangered')\n",
    "        ax.plot(storage_sensitivity['cost_multiplier'], \n",
    "               storage_sensitivity['baseline_earnings'], \n",
    "               marker='s', linewidth=2, label='Baseline Strategy', color='steelblue')\n",
    "        \n",
    "        ax.set_xlabel('Storage Cost Multiplier', fontsize=12)\n",
    "        ax.set_ylabel('Net Earnings ($)', fontsize=12)\n",
    "        ax.set_title(f'Storage Cost Sensitivity\\n{CURRENT_COMMODITY.upper()} - {MODEL_VERSION}', \n",
    "                    fontsize=14, fontweight='bold')\n",
    "        ax.legend()\n",
    "        ax.grid(True, alpha=0.3)\n",
    "        ax.axvline(x=1.0, color='black', linestyle='--', linewidth=1, alpha=0.5, label='Baseline Cost')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        \n",
    "        storage_path = f'{VOLUME_PATH}/storage_sensitivity_{CURRENT_COMMODITY}_{MODEL_VERSION}.png'\n",
    "        plt.savefig(storage_path, dpi=300, bbox_inches='tight')\n",
    "        print(f\"✓ Saved: {storage_path}\")\n",
    "        plt.close()\n",
    "        \n",
    "        # ----------------------------------------------------------------------\n",
    "        # Save Results\n",
    "        # ----------------------------------------------------------------------\n",
    "        print(f\"\\nSaving results...\")\n",
    "        \n",
    "        sensitivity_results = {\n",
    "            'commodity': CURRENT_COMMODITY,\n",
    "            'model_version': MODEL_VERSION,\n",
    "            'consensus_sensitivity': consensus_sensitivity,\n",
    "            'transaction_sensitivity': transaction_sensitivity,\n",
    "            'storage_sensitivity': storage_sensitivity,\n",
    "            'optimal_consensus_params': {\n",
    "                'consensus_threshold': best_params['consensus_threshold'],\n",
    "                'min_return': best_params['min_return'],\n",
    "                'net_earnings': best_params['net_earnings']\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        with open(MODEL_DATA_PATHS['sensitivity_results'], 'wb') as f:\n",
    "            pickle.dump(sensitivity_results, f)\n",
    "        \n",
    "        print(f\"✓ Saved: {MODEL_DATA_PATHS['sensitivity_results']}\")\n",
    "        \n",
    "        # Save as CSVs\n",
    "        consensus_csv = f'{VOLUME_PATH}/consensus_sensitivity_{CURRENT_COMMODITY}_{MODEL_VERSION}.csv'\n",
    "        consensus_sensitivity.to_csv(consensus_csv, index=False)\n",
    "        print(f\"✓ Saved: {consensus_csv}\")\n",
    "        \n",
    "        trans_csv = f'{VOLUME_PATH}/transaction_sensitivity_{CURRENT_COMMODITY}_{MODEL_VERSION}.csv'\n",
    "        transaction_sensitivity.to_csv(trans_csv, index=False)\n",
    "        print(f\"✓ Saved: {trans_csv}\")\n",
    "        \n",
    "        storage_csv = f'{VOLUME_PATH}/storage_sensitivity_{CURRENT_COMMODITY}_{MODEL_VERSION}.csv'\n",
    "        storage_sensitivity.to_csv(storage_csv, index=False)\n",
    "        print(f\"✓ Saved: {storage_csv}\")\n",
    "        \n",
    "        print(f\"\\n✓ Sensitivity analysis complete for {MODEL_VERSION}\")\n",
    "    \n",
    "    print(f\"\\n{'=' * 80}\")\n",
    "    print(f\"✓ {CURRENT_COMMODITY.upper()} COMPLETE\")\n",
    "    print(f\"{'=' * 80}\")\n",
    "\n",
    "# COMMAND ----------\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ALL SENSITIVITY ANALYSES COMPLETE\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"Commodities analyzed: {', '.join([c.upper() for c in COMMODITY_CONFIGS.keys()])}\")\n",
    "print(\"\\n✓ Sensitivity analysis complete for all commodities and models\")"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "08_sensitivity_analysis",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
